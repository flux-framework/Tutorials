{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<center><img src=\"Flux-logo.svg\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "# Module 2: Using Flux for traditional and hierarchical schedulinng\n",
    "\n",
    "Flux provides powerful and advanced scheduling capabilities that are important for exascale systems like El Capitan. In this module, we demonstrate:\n",
    "1. Traditional batch scheduling with Flux (similar to what is provided by other schedulers like Slurm)\n",
    "2. Hierarchical scheduling with Flux to achieve higher throughput (novel capability of Flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional batch scheduling with Flux\n",
    "\n",
    "In traditional batch scheduling (e.g., what Slurm provides), users send requests for resources and jobs to a centralized service (i.e., the scheduler), which stores the requests in a queue and fulfills them as possible.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/single-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Vanessa Sochat for Flux Framework Components documentation</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "Traditional schedulers provide 3 main operations:\n",
    "1. Submitting jobs\n",
    "2. Running distributed applications within a job\n",
    "3. Querying the status of jobs or canceling running jobs\n",
    "\n",
    "We use Flux to perform these traditional batch scheduling operations in the order shown in this table:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Operation</th>\n",
    "        <th>Slurm</th>\n",
    "        <th>Flux</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Submitting jobs</td>\n",
    "        <td><code>sbatch</code></td>\n",
    "        <td><code>flux batch</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Submiting interactive jobs</td>\n",
    "        <td><code>salloc</code></td>\n",
    "        <td><code>flux alloc</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Running distributed applications with waiting for completion</td>\n",
    "        <td><code>srun</code></td>\n",
    "        <td><code>flux run</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Running distrubted applications without waiting for completion</td>\n",
    "        <td>N/A</td>\n",
    "        <td><code>flux submit</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Querying the status of jobs</td>\n",
    "        <td><code>squeue</code>/<code>scontrol show job <i>job_id</i></code></td>\n",
    "        <td><code>flux jobs</code>/<code>flux job info <i>job_id</i></code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Cancelling running jobs</td>\n",
    "        <td><code>scancel</code></td>\n",
    "        <td><code>flux cancel</code></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "For a more comprehensive cross-reference between Slurm, Flux, and other schedulers, check out LLNL's [Batch System Cross-Reference Guides](https://hpc.llnl.gov/banks-jobs/running-jobs/batch-system-cross-reference-guides)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting jobs\n",
    "\n",
    "Similar to Slurm's `sbatch`, users submit non-interactive, batch script-based jobs using `flux batch`. To see how `flux batch` works, let's start by looking at the batch script `sleep_batch.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='sleep_batch.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to a Slurm batch script, a Flux batch script consists of two main sections:\n",
    "1. A set of Flux directives defining the arguments that should be passed to `flux batch`\n",
    "2. The commands defining the job\n",
    "\n",
    "In `sleep_batch.sh`, there are 3 directives:\n",
    "1. `#FLUX: --nodes=2`: tells Flux to create an allocation of 2 nodes for this job\n",
    "2. `#FLUX: --nslots=2`: tells Flux to reserve 2 slots total for this job\n",
    "3. `#FLUX: --cores-per-slot=1`: tells Flux to reserve 1 core per slot for this job\n",
    "\n",
    "The rest of this batch script contains several `echo` commands follwed by 2 `flux run` commands that will sleep for 30 seconds each.\n",
    "\n",
    "Let's try to run our batch job with `flux batch`. Note that we provide two extra flags to `flux batch`. Similar to Slurm, flags passed on the command line are added to the set of flags specified in the Flux directives. In this case, the `--output=kvs` and `--error=kvs` flags redirect `stdout` and `stderr` to the Flux key-value store (which will be covered in [Module 3](./03_flux_framework.ipynb)), which allows it to be tracked by the `flux watch` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch --output=kvs --error=kvs ./sleep_batch.sh\n",
    "!flux watch $(flux job last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting interactive jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Slurm's `salloc`, users can submit interactive jobs using `flux alloc`. When launching an interactive job, you can request resources using the same flags that you would pass to `flux batch` (e.g., `-N` for requesting a number of nodes).\n",
    "\n",
    "Due to Jupyter's lack of a pseudo-terminal, we cannot show `flux alloc` in this notebook. So, we will open a terminal in Jupyter. To do so, click on `FILE -> NEW -> TERMINAL`. Then, copy and paste the following commands into the terminal:\n",
    "\n",
    "```bash\n",
    "$ flux alloc --nodes=2 --nslots=2 --cores-per-slot=1\n",
    "$ ./hello-batch.sh\n",
    "$ cat /tmp/hello-batch-1.out\n",
    "$ cat /tmp/hello-batch-2.out\n",
    "$ cat /tmp/hello-batch-3.out\n",
    "$ cat /tmp/hello-batch-4.out\n",
    "```\n",
    "\n",
    "The `hello-batch.sh` script (shown below) runs 4 `flux submit` commands that print output to the 4 files that we run `cat` on. It then runs `flux job wait --all`, which waits for all 4 `flux submit` commands to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='hello-batch.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: connecting to an existing Flux instance using flux proxy\n",
    "\n",
    "TODO check if this text or original example should be put in supplement\n",
    "\n",
    "One cool feature that Flux provides is the ability to connect to an existing Flux instance/allocation from any other node of the system using `flux proxy`. To use this command, we first need to get the ID of the Flux instance we want to connect to. Assuming the interactive job we just launched is still running, we can get the job ID (which is the same as the instance ID) using `flux jobs`. Once we have that ID, we can run `flux proxy <ID>` to connect to that Flux instance.\n",
    "\n",
    "Once we're connected to the interactive allocation, we can run the following job in one terminal:\n",
    "```bash\n",
    "$ flux run --nodes=1 sleep inf\n",
    "```\n",
    "\n",
    "Then, in the other terminal, we should be able to see that `flux run` by running `flux jobs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running distributed applications with waiting for completion\n",
    "\n",
    "Similar to Slurm's `srun`, users can run distributed (e.g., MPI) applications and wait for completion using `flux run`. To see how `flux run` works, let's run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux run -n 4 --label-io --time-limit=5s --env-remove=LD_LIBRARY_PATH hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command does the following:\n",
    "1. Remove `LD_LIBRARY_PATH` from the environment of each `hostname` program (specified by `--env-remove=LD_LIBRARY_PATH`)\n",
    "2. Launch 4 copies of the `hostname` program and waits for all of them to complete before finishing (specified by `-n 4`)\n",
    "3. Prepend the task rank to each line of `stdout` and `stderr` (specified by `--label-io`)\n",
    "4. Kill the job automatically after 5 seconds (specified by `--time-limit=5s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running distributed applications without waiting for completion\n",
    "\n",
    "Unlike Slurm, Flux provides the `flux submit` command to run distributed (e.g., MPI) applications **without** waiting for the application to complete. This allows users to easily run multiple distributed applications in parallel *under the same job*, which is important for many modern HPC applications such as workflows.\n",
    "\n",
    "To see how `flux submit` works, let's look at `hello-batch.sh` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='hello-batch.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this script runs 4 different `flux submit` commands, each of which prints a message to a different file. If this script were to use `flux run`, these commands would run one after the other. Instead, by using `flux submit` instead of `flux run`, Flux can run all of these `echo` programs in parallel (assuming there are enough resources to do so). This means the job that runs this script can (theoretically) complete **4 times faster** than it could using `flux run`.\n",
    "\n",
    "Because `flux submit` does not wait for jobs, batch scripts that use this command must use another approach for waiting on job completion. To help with this scenario, Flux provides the `flux job wait` command, which waits for the specified job/program (or all of them if the `--all` flag is provided) to complete. *Note that, to use `flux job wait`, you must pass the `--flags=waitable` flag to your Flux command.*\n",
    "\n",
    "To see `flux submit` in action, let's run `hello-batch.sh` through `flux batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch --flags=waitable --out /tmp/flux-batch.out -N2 ./hello-batch.sh\n",
    "!flux job wait $(flux job last)\n",
    "!cat /tmp/hello-batch-1.out\n",
    "!cat /tmp/hello-batch-2.out\n",
    "!cat /tmp/hello-batch-3.out\n",
    "!cat /tmp/hello-batch-4.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux also includes 2 more convenient options for submitting multiple copies of the same or similar jobs in parallel.\n",
    "\n",
    "First, there is `flux bulksubmit`. This command enqueues jobs based on a set of inputs which are substituted on the command line, similar to `xargs` and the GNU `parallel` utility. Unlike those programs, the jobs created by `flux bulksubmit` have access to the resources of an entire Flux instance instead of only the local system.\n",
    "\n",
    "Let's run a simple example of `flux bulksubmit` to see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux bulksubmit --watch --wait echo {} ::: foo bar baz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flags provided to `flux bulksubmit` tell it to print the output of each job to the terminal and wait for all the jobs to finish before returning.\n",
    "\n",
    "Second, there is the `-cc` flag to `flux submit`. This flag tells Flux to spawn multiple copies of a single command with different job IDs. Unlike `flux bulksubmit`, you cannot substitute arbitrary values into the command. Instead, when using the `-cc` flag, you can only substitute the job ID using `{cc}`.\n",
    "\n",
    "Let's run a simple example of `flux submit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit --cc=1-10 --watch hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the status of jobs\n",
    "\n",
    "Similar to Slurm's `squeue`, users can check the status of all their jobs using `flux jobs`. To see what information `flux jobs` gives us, let's start a bunch of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit hostname\n",
    "!flux submit -N1 -n2 sleep inf\n",
    "!flux run hostname\n",
    "!flux run /bin/false\n",
    "!flux run -n4 --label-io --time-limit=5s --env-remove=LD_LIBRARY_PATH hostname\n",
    "!flux submit --cc=1-10 --watch hostname\n",
    "!flux submit -N1 -n2 sleep inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the status of all pending, running, or completed jobs, we will run `flux jobs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can also filter or expand what jobs they see by providing flags to `flux jobs`. The full list of flags can be obtained using `flux jobs --help` (for usage statement style) or `flux help jobs` (for man page style).\n",
    "\n",
    "Let's run the two code cells below to see information on all completed jobs and failed jobs respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -f failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canceling running jobs\n",
    "\n",
    "Similar to Slurm's `scancel`, users can kill running jobs and cancel pending jobs using `flux cancel`. This command can be used to kill/cancel individual jobs or all jobs.\n",
    "\n",
    "Let's run the command below to cancel the last submitted job. Note that `flux job last` gives us the ID of the most recently submitted job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux cancel $(flux job last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the `flux cancel --all` to cancel all running and pending jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux cancel --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical scheduling with Flux\n",
    "\n",
    "With traditional batch schedulers (e.g., Slurm), all job requests from all users are submitted to one centralized service. In this case, the maximum job throughput is one job per second.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/single-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Vanessa Sochat for Flux Framework Components documentation</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "The throughput of this approach is limited by the scheduler's ability to process a single job. To improve throughput, Flux introduces the ability to launch multiple Flux instances within an existing Flux instance. This creates a hierarchy of Flux instances across which job requests can be distributed. For example, let's say we create a Flux instance that has control of some number of nodes. We then create 3 child instances (each with its own scheduler and queue). By scheduling across this hierarchy of instances, we get a throughput of 1x3, or 3 jobs per second.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/instance-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Vanessa Sochat for Flux Framework Components documentation</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "By leveraging a hierarchy of Flux instances to achieve a divide-and-conquer approach to scheduling, we can exponentially increase throughput. The figure below (from our [learning guide](https://flux-framework.readthedocs.io/en/latest/guides/learning_guide.html#fully-hierarchical-resource-management-techniques)) shows this exponential increase in an actual experiment. We submit 500 jobs/second using only a three-level hierarchy, whereas a centralized scheduler (1-Level in the figure) achieves only one 1 job/second.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/scaled-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image from <a href=\"https://flux-framework.readthedocs.io/en/latest/guides/learning_guide.html#fully-hierarchical-resource-management-techniques\">Flux learning guide</a></i></figcaption>\n",
    "</figure>\n",
    "\n",
    "There are different ways to create hierarchies of Flux instances. In this tutorial, we will focus on 2 of them:\n",
    "1. Nested invocations of `flux batch`\n",
    "2. The `flux tree` command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested invocations of flux batch\n",
    "\n",
    "As mentioned in the [Traditional batch scheduling with Flux]() section, `flux batch` is the command used to submit non-interactive, batch script-based jobs to Flux.\n",
    "\n",
    "The `flux batch` command can be invoked in a nested fashion within a batch script run by another `flux batch` command. When a job submitted with `flux batch` starts running, Flux creates a new Flux instance over the resources reserved for that job. In other words, before starting the script that the user provides, `flux batch` creates a new child in the hierarchy of Flux instances. Since a Flux instance has the same capabilities no matter where it lies in the hierarchy, this newly created instance can schedule its resources in the same way that a system-wide Flux instance can. As a result, the newly created Flux instance can be used to perform additional `flux batch` commands over its subset of the resources.\n",
    "\n",
    "To show this in action, let's look at `sub_job1.sh` and `sub_job2.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='sub_job1.sh', language='bash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='sub_job2.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scheduled with `flux batch`, `sub_job1.sh` will run in a new Flux instance. It will then run `flux batch` again to run `sub_job2.sh`. Because the second `flux batch` command is within `sub_job1.sh`, the job request produced by the second `flux batch` command will go to the scheduler of the child Flux instance instead of the parent Flux instance.\n",
    "\n",
    "We can see this in action by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch -N1 ./sub_job1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have submitted `sub_job1.sh`, we can look at the hierarchy for all the jobs we've run using `flux pstree`. Normally, this command can be used to show jobs in a Flux instance. However, since we are running in a Jupyter notebook, this command will have limited functionality. So, instead of just running the single command, we will run `flux pstree -a` to look at **all** jobs. In a more complex environment with more jobs, this command would show a deeper nesting. You can see examples of more complex outputs [here](https://flux-framework.readthedocs.io/en/latest/jobs/hierarchies.html?h=pstree#flux-pstree-command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux pstree -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The flux tree command\n",
    "\n",
    "`flux tree` is a prototype tool that allows you to easily create a hierarchy of Flux instances and submit work to different levels it. Alternatively, it can be thought of as a way to create a nested hierarchy of jobs that scale out.\n",
    "\n",
    "Let's run the command, look at the output, and talk about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux tree -T2x2 -J 4 -N 1 -c 4 -o ./tree.out -Q easy:fcfs hostname \n",
    "!cat ./tree.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, we run `flux tree` and look at the output file. The flags to `flux tree` do the following:\n",
    "* `-T2x2`: spawn 2 Flux instances under the current instance and then spawn 2 more Flux instances under each of the other 2 (resulting in 4 leaf instances)\n",
    "* `-N 1`: deploy this hierarchy across 1 node\n",
    "* `-c 4`: deploy this hierarchy with 4 cores per node\n",
    "* `-o ./tree.out`: write performance data for the hierarchy to `./tree.out`\n",
    "* `-Q easy:fcfs`: use the EASY scheduling policy (backfilling with reservations) in the first level of the hierarchy and use the fcfs policy (first come, first served) in the second (i.e., leaf) level\n",
    "\n",
    "With these flags, `flux tree` creates the hierarchy shown in the image below, with each leaf-level instance scheduling the `hostname` program.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/flux-tree.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Ian Lumsden based on images by Vanessa Sochat</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "For this tutorial, we show `flux tree` with a relatively simple job (i.e., `hostname`). However, since this command accepts any valid jobspec that can be recognized by `flux submit`, it can be used to rapidly deploy much more complex scenarios, including scenarios where different programs are run on each leaf-level instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This concludes Module 2.\n",
    "\n",
    "In this module, we demonstrated how to:\n",
    "1. Use Flux for traditional batch scheduling similar to what is provided by other schedulers like Slurm\n",
    "2. Use Flux for hierarchical scheduling to achieve greater scheduling throughput\n",
    "\n",
    "To continue with the tutorial, open [Module 3](./03_flux_framework.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

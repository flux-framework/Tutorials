{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional and Hierarchical Schedulinng using Flux\n",
    "\n",
    "As mentioned in the intro video, Flux provides powerful and advanced scheduling capabilities that are important for Exascale systems like El Capitan. In this notebook, we will show how to:\n",
    "1. Use Flux for traditional batch scheduling similar to what is provided by other schedulers like Slurm\n",
    "2. Use Flux for hierarchical scheduling to achieve greater scheduling throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional batch scheduling with Flux\n",
    "\n",
    "In traditional batch scheduling (e.g., what Slurm provides), users send requests for resources and jobs to a centralized service (i.e., the scheduler), which stores the requests in a queue and fulfills them as possible.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/single-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Vanessa Sochat for Flux Framework Components documentation</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "To allow for this type of scheduling, schedulers like Slurm provide 3 main operations:\n",
    "1. Submitting jobs\n",
    "2. Running distributed applications within a job\n",
    "3. Querying the status of jobs or canceling running jobs\n",
    "\n",
    "Although Flux's real benefits come from other types of scheduling (e.g., hierarchical and graph-based), Flux is still capable of handling these traditional scheduling operations. In this section, we will cover how to use Flux to perform these traditional batch scheduling operations. We will cover these operations in the order shown in the table below:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Operation</th>\n",
    "        <th>Slurm</th>\n",
    "        <th>Flux</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Submit a job</td>\n",
    "        <td><code>sbatch</code></td>\n",
    "        <td><code>flux batch</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Submit an interactive job</td>\n",
    "        <td><code>salloc</code></td>\n",
    "        <td><code>flux alloc</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Run distributed application and wait for completion</td>\n",
    "        <td><code>srun</code></td>\n",
    "        <td><code>flux run</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Run distrubted application and <b>don't</b> wait for completion</td>\n",
    "        <td>N/A</td>\n",
    "        <td><code>flux submit</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Query the status of jobs</td>\n",
    "        <td><code>squeue</code>/<code>scontrol show job <i>job_id</i></code></td>\n",
    "        <td><code>flux jobs</code>/<code>flux job info <i>job_id</i></code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Cancel running jobs</td>\n",
    "        <td><code>scancel</code></td>\n",
    "        <td><code>flux cancel</code></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting jobs\n",
    "\n",
    "Similar to Slurm's `sbatch`, users submit non-interactive, batch script-based jobs using `flux batch`. To see how `flux batch` works, let's start by looking at the batch script `sleep_batch.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='sleep_batch.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to a Slurm batch script, a Flux batch script consists of two main sections:\n",
    "1. A set of Flux directives defining the arguments that should be passed to `flux batch`\n",
    "2. The commands defining the job\n",
    "\n",
    "In `sleep_batch.sh`, there are 3 directives:\n",
    "1. `#FLUX: --nodes=2`: tells Flux to create an allocation of 2 nodes for this job\n",
    "2. `#FLUX: --nslots=2`: tells Flux to reserve 2 slots total for this job\n",
    "3. `#FLUX: --cores-per-slot=1`: tells Flux to reserve 1 core per slot for this job\n",
    "\n",
    "The rest of this batch script contains several `echo` commands follwed by 2 `flux run` commands that will sleep for 30 seconds each.\n",
    "\n",
    "Let's try to run our batch job with `flux batch`. Note that we provide an extra `--flags=waitable` flag to `flux batch`. Similar to Slurm, flags passed on the command line are added to the set of flags specified in the Flux directives. In this case, `--flags=waitable` allows us run `flux job wait` to wait for the completion of `flux batch` and see `stdout` and `stderr` on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch --flags=waitable ./sleep_batch.sh\n",
    "!flux job wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting interactive jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Slurm's `salloc`, users can submit interactive jobs using `flux alloc`. When launching an interactive job, you can request resources using the same flags that you would pass to `flux batch` (e.g., `-N` for requesting a number of nodes).\n",
    "\n",
    "Due to Jupyter's lack of a pseudo-terminal, we cannot show `flux alloc` in this notebook. So, we will open a terminal in Jupyter. To do so, click on `FILE -> NEW -> TERMINAL`. Then, copy and paste the following commands into the terminal:\n",
    "\n",
    "```bash\n",
    "$ flux alloc --nodes=2 --nslots=2 --cores-per-slot=1\n",
    "$ ./hello-batch.sh\n",
    "$ cat /tmp/hello-batch-1.out\n",
    "$ cat /tmp/hello-batch-2.out\n",
    "$ cat /tmp/hello-batch-3.out\n",
    "$ cat /tmp/hello-batch-4.out\n",
    "```\n",
    "\n",
    "The `hello-batch.sh` script (shown below) runs 4 `flux submit` commands that print output to the 4 files that we run `cat` on. It then runs `flux job wait --all`, which waits for all 4 `flux submit` commands to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='hello-batch.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing distributed applications with waiting for completion\n",
    "\n",
    "Similar to Slurm's `srun`, users can run distributed (e.g., MPI) applications and wait for completion using `flux run`. To see how `flux run` works, let's run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux run -n 4 --label-io --time-limit=5s --env-remove=LD_LIBRARY_PATH hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command does the following:\n",
    "1. Remove `LD_LIBRARY_PATH` from the environment of each `hostname` program (specified by `--env-remove=LD_LIBRARY_PATH`)\n",
    "2. Launch 4 copies of the `hostname` program and waits for all of them to complete before finishing (specified by `-n 4`)\n",
    "3. Prepend the task rank to each line of `stdout` and `stderr` (specified by `--label-io`)\n",
    "4. Kill the job automatically after 5 seconds (specified by `--time-limit=5s`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running distributed applications without waiting for completion\n",
    "\n",
    "Unlike Slurm, Flux provides the `flux submit` command to run distributed (e.g., MPI) applications **without** waiting for the application to complete. This allows users to easily run multiple distributed applications in parallel *under the same job*, which is important for many modern HPC applications such as workflows.\n",
    "\n",
    "To see how `flux submit` works, let's look at `hello-batch.sh` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='hello-batch.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this script runs 4 different `flux submit` commands, each of which prints a message to a different file. If this script were to use `flux run`, these commands would run one after the other. Instead, by using `flux submit` instead of `flux run`, Flux can run all of these `echo` programs in parallel (assuming there are enough resources to do so). This means the job that runs this script can (theoretically) complete **4 times faster** than it could using `flux run`.\n",
    "\n",
    "Because `flux submit` does not wait for jobs, batch scripts that use this command must use another approach for waiting on job completion. To help with this scenario, Flux provides the `flux job wait` command, which waits for the specified job/program (or all of them if the `--all` flag is provided) to complete. *Note that, to use `flux job wait`, you must pass the `--flags=waitable` flag to your Flux command.*\n",
    "\n",
    "To see `flux submit` in action, let's run `hello-batch.sh` through `flux batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch --flags=waitable --out /tmp/flux-batch.out -N2 ./hello-batch.sh\n",
    "!flux job wait\n",
    "!cat /tmp/hello-batch-1.out\n",
    "!cat /tmp/hello-batch-2.out\n",
    "!cat /tmp/hello-batch-3.out\n",
    "!cat /tmp/hello-batch-4.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux also includes 2 more convenient options for submitting multiple copies of the same or similar jobs in parallel.\n",
    "\n",
    "First, there is `flux bulksubmit`. This command enqueues jobs based on a set of inputs which are substituted on the command line, similar to `xargs` and the GNU `parallel` utility. Unlike those programs, the jobs created by `flux bulksubmit` have access to the resources of an entire Flux instance instead of only the local system.\n",
    "\n",
    "Let's run a simple example of `flux bulksubmit` to see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux bulksubmit --watch --wait echo {} ::: foo bar baz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flags provided to `flux bulksubmit` tell it to print the output of each job to the terminal and wait for all the jobs to finish before returning.\n",
    "\n",
    "Second, there is the `-cc` flag to `flux submit`. This flag tells Flux to spawn multiple copies of a single command with different job IDs. Unlike `flux bulksubmit`, you cannot substitute arbitrary values into the command. Instead, when using the `-cc` flag, you can only substitute the job ID using `{cc}`.\n",
    "\n",
    "Let's run a simple example of `flux submit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit --cc=1-10 --watch hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the status of jobs\n",
    "\n",
    "Similar to Slurm's `squeue`, users can check the status of all their jobs using `flux jobs`. To see what information `flux jobs` gives us, let's start a bunch of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit hostname\n",
    "!flux submit -N1 -n2 sleep inf\n",
    "!flux run hostname\n",
    "!flux run /bin/false\n",
    "!flux run -n4 --label-io --time-limit=5s --env-remove=LD_LIBRARY_PATH hostname\n",
    "!flux submit --cc=1-10 --watch hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the status of all pending, running, or completed jobs, we will run `flux jobs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can also filter or expand what jobs they see by providing flags to `flux jobs`. The full list of flags can be obtained using `flux jobs --help` (for usage statement style) or `flux help jobs` (for man page style).\n",
    "\n",
    "Let's run the two code cells below to see information on all completed jobs and failed jobs respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -f failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canceling running jobs\n",
    "\n",
    "Similar to Slurm's `scancel`, users can kill running jobs and cancel pending jobs using `flux cancel`. This command can be used to kill/cancel individual jobs or all jobs.\n",
    "\n",
    "Let's run the command below to cancel the last submitted job. Note that `flux job last` gives us the ID of the most recently submitted job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux cancel $(flux job last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the `flux cancel --all` to cancel all running and pending jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux cancel --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical scheduling with Flux\n",
    "\n",
    "With traditional batch schedulers (e.g., Slurm), all job requests from all users are submitted to one centralized service. Note that our maximum job throughput is one job per second.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/single-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Vanessa Sochat for Flux Framework Components documentation</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "The throughput of this approach is limited by the scheduler's ability to process a single job. To improve throughput, Flux introduces the ability to launch multiple Flux instances within an existing Flux instance. This creates a hierarchy of Flux instances across which job requests can be distributed. For example, let's say we create a Flux instance that has control of some number of nodes. We then create 3 child instances (each with its own scheduler and queue). By scheduling across this hierarchy of instances, we get a throughput of 1x3, or 3 jobs per second.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/instance-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Vanessa Sochat for Flux Framework Components documentation</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "By leveraging a hierarchy of Flux instances to achieve a divide-and-conquer approach to scheduling, we can exponentially increase throughput. The figure below (from our [learning guide](https://flux-framework.readthedocs.io/en/latest/guides/learning_guide.html#fully-hierarchical-resource-management-techniques)) shows this exponential increase in an actual experiment. We were able to submit 500 jobs/second using only a three-level hierarchy, whereas a centralized scheduler (1-Level in the figure) was only able to achieve one 1 job/second.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/scaled-submit.png\">\n",
    "<figcaption>\n",
    "<i>Image from <a href=\"https://flux-framework.readthedocs.io/en/latest/guides/learning_guide.html#fully-hierarchical-resource-management-techniques\">Flux learning guide</a></i></figcaption>\n",
    "</figure>\n",
    "\n",
    "There are several ways to create hierarchies of Flux instances. In this tutorial, we will focus on 2 of them:\n",
    "1. Through nested invocations of `flux batch`\n",
    "2. Through the prototype `flux tree` command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical scheduling with flux batch\n",
    "\n",
    "As mentioned above, `flux batch` is the command used to submit non-interactive, batch script-based jobs to Flux. When a job submitted with `flux batch` starts running, Flux will create a new Flux instance over the resources reserved for that job. In other words, before even getting to the script that the user provides, `flux batch` creates a new child in the hierarchy of Flux instances. Since a Flux instance has the same capabilities no matter where it lies in the hierarchy, this newly created instance can schedule its resources in the same way that a system-wide Flux instance can. As a result, the newly created Flux instance can be used to perform additional `flux batch` commands over its subset of the resources.\n",
    "\n",
    "To show this in action, let's look at `sub_job1.sh` and `sub_job2.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='sub_job1.sh', language='bash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "Code(filename='sub_job2.sh', language='bash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scheduled with `flux batch`, `sub_job1.sh` will run in a new Flux instance. It will then run `flux batch` again to run `sub_job2.sh`. Because the second `flux batch` command is within `sub_job1.sh`, the job request produced by the second `flux batch` command will go to the scheduler of the child Flux instance instead of the parent Flux instance.\n",
    "\n",
    "We can see this in action by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch -N1 ./sub_job1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've submitted `sub_job1.sh`, we can look at the hierarchy for all the jobs we've run using `flux pstree`. Normally, this command can be used to show jobs in a Flux instance. However, since we are running in a Jupyter notebook, this command will have limited functionality. So, instead of just running the single command, we will run `flux pstree -a` to look at **all** jobs. In a more complex environment with more jobs, this command would show a deeper nesting. You can see examples of more complex outputs [here](https://flux-framework.readthedocs.io/en/latest/jobs/hierarchies.html?h=pstree#flux-pstree-command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux pstree -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical scheduling with flux tree\n",
    "\n",
    "`flux tree` is a prototype tool that allows you to easily create a hierarchy of Flux instances and submit work to different levels it. Alternatively, it can be thought of as a way to create a nested hierarchy of jobs that scale out.\n",
    "\n",
    "Let's run the command, look at the output, and talk about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux tree -T2x2 -J 4 -N 1 -c 4 -o ./tree.out -Q easy:fcfs hostname \n",
    "!cat ./tree.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, we run `flux tree` and look at the output file. The flags to `flux tree` do the following:\n",
    "* `-T2x2`: spawn 2 Flux instances under the current instance and then spawn 2 more Flux instances under each of the other 2 (resulting in 4 leaf instances)\n",
    "* `-N 1`: deploy this hierarchy across 1 node\n",
    "* `-c 4`: deploy this hierarchy with 4 cores per node\n",
    "* `-o ./tree.out`: write performance data for the hierarchy to `./tree.out`\n",
    "* `-Q easy:fcfs`: use the EASY scheduling policy (backfilling with reservations) in the first level of the hierarchy and use the fcfs policy (first come, first served) in the second (i.e., leaf) level\n",
    "\n",
    "With these flags, `flux tree` creates the hierarchy shown in the image below, with each leaf-level instance scheduling the `hostname` program.\n",
    "\n",
    "<figure>\n",
    "<img src=\"img/flux-tree.png\">\n",
    "<figcaption>\n",
    "<i>Image created by Ian Lumsden based on images by Vanessa Sochat</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "For this tutorial, we show `flux tree` with a relatively simple job (i.e., `hostname`). However, since this command accepts any valid jobspec that can be recognized by `flux submit`, it can be used to rapidly deploy much more complex scenarios, including scenarios where different programs are run on each leaf-level instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This concludes this notebook.\n",
    "\n",
    "In this notebook, we demonstrated how to:\n",
    "1. Use Flux for traditional batch scheduling similar to what is provided by other schedulers like Slurm\n",
    "2. Use Flux for hierarchical scheduling to achieve greater scheduling throughput\n",
    "\n",
    "To continue with the tutorial, open [03_flux_framework.ipynb](./03_flux_framework.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

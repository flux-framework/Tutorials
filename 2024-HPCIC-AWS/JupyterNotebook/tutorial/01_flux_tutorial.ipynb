{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2507d149-dcab-458a-a554-37388e0ee13a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div>\n",
    "<center><img src=\"Flux-logo.svg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e867ba-f689-4301-bb60-9a448556bb84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Welcome to the Flux Tutorial\n",
    "\n",
    "> What is Flux Framework? ü§îÔ∏è\n",
    " \n",
    "Flux is a flexible framework for resource management, built for your site. The framework consists of a suite of projects, tools, and libraries that may be used to build site-custom resource managers for High Performance Computing centers and cloud environments. Flux is a next-generation resource manager and scheduler with many transformative capabilities like hierarchical scheduling and resource management (you can think of it as \"fractal scheduling\") and directed-graph based resource representations.\n",
    "\n",
    "## I'm ready! How do I do this tutorial? üòÅÔ∏è\n",
    "\n",
    "This tutorial is split into 3 chapters, each of which has a notebook:\n",
    "* [Chapter 1: Getting started with Flux](./01_flux_tutorial.ipynb) (you're already here, it's this notebook!)\n",
    "* [Chapter 2: Flux Plumbing](./02_flux_framework.ipynb)\n",
    "* [Chapter 3: Lessons learned, next steps, and discussion](./03_flux_tutorial_conclusions.ipynb)\n",
    "\n",
    "And if you have some extra time and interest, we have supplementary chapters to teach you about advanced (often experimental, or under development) features:\n",
    "\n",
    "* [Supplementary Chapter 1: Using DYAD to accelerate distributed Deep Learning (DL) training](./supplementary/dyad/dyad_dlio.ipynb)\n",
    "\n",
    "Let's get started! To provide some brief, added background on Flux and a bit more motivation for our tutorial, \"Shift+Enter\" the cell below to watch our YouTube video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d71ecd22-8552-4b4d-9bc4-61d86f8d33fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"640\" height=\"360\" \n",
       "    src=\"https://www.youtube.com/embed/YIwt51dyXOE\" \n",
       "    title=\"YouTube video player\" \n",
       "    frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" \n",
       "    allowfullscreen>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"640\" height=\"360\" \n",
    "    src=\"https://www.youtube.com/embed/YIwt51dyXOE\" \n",
    "    title=\"YouTube video player\" \n",
    "    frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" \n",
    "    allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e82c38-8465-49ac-ae2b-b0bb56a79ec9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "# Getting started with Flux\n",
    "\n",
    "The code and examples that this tutorial is based on can be found at [flux-framework/Tutorials](https://github.com/flux-framework/Tutorials/tree/master/2024-HPCIC-AWS). You can also find python examples in the `flux-workflow-examples` directory from the sidebar navigation in this JupyterLab instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33fef6-278c-4996-8534-fd15e548b338",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<span style=\"font-weight:600\">Tip:</span> Did you know you can get help for flux or a flux command? For example, try \"flux help\" and \"flux help jobs\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d616de-70cd-4090-bd43-ffacb5ade1f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: flux [OPTIONS] COMMAND ARGS\n",
      "  -h, --help             Display this message.\n",
      "  -v, --verbose          Be verbose about environment and command search\n",
      "  -V, --version          Display command and component versions\n",
      "  -p, --parent           Set environment of parent instead of current instance\n",
      "\n",
      "For general Flux documentation, please visit\n",
      "    https://flux-framework.readthedocs.io\n",
      "\n",
      "run and submit jobs, allocate resources\n",
      "   submit             submit a job to a Flux instance\n",
      "   run                run a Flux job interactively\n",
      "   bulksubmit         submit jobs in bulk to a Flux instance\n",
      "   alloc              allocate a new Flux instance for interactive use\n",
      "   batch              submit a batch script to Flux\n",
      "\n",
      "list and interact with jobs\n",
      "   jobs               list jobs submitted to Flux\n",
      "   top                display running Flux jobs\n",
      "   pstree             display job hierarchies\n",
      "   cancel             cancel one or more jobs\n",
      "   pgrep/pkill        search or cancel matching jobs\n",
      "   job                get job status, info, etc (see: flux help job)\n",
      "   proxy              proxy connections to Flux jobs and instances\n",
      "   watch              monitor one or more Flux jobs\n",
      "   update             update active Flux jobs\n",
      "\n",
      "get resource, queue and other instance information\n",
      "   resource           list/manipulate Flux resource status\n",
      "   queue              list and manipulate flux queues\n",
      "   overlay            Show flux overlay network status\n",
      "   uptime             Tell how long Flux has been up and running\n",
      "\n",
      "other useful commands\n",
      "   start              bootstrap a local Flux instance\n",
      "   version            Display flux version information\n",
      "   config             Manage/query Flux configuration\n",
      "   env                Print the flux environment or execute a command inside it\n",
      "   hostlist           fetch, combine, and manipulate Flux hostlists\n",
      "\n",
      "See 'flux help COMMAND' for more information about a specific command.\n"
     ]
    }
   ],
   "source": [
    "!flux help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e54f640-283a-4523-8dde-9617fd6ef0c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLUX-JOBS(1)                       flux-core                      FLUX-JOBS(1)\n",
      "\n",
      "NAME\n",
      "       flux-jobs - list jobs submitted to Flux\n",
      "\n",
      "SYNOPSIS\n",
      "       flux jobs [OPTIONS] [JOBID ...]\n",
      "\n",
      "DESCRIPTION\n",
      "       flux  jobs is used to list jobs run under Flux. By default only pending\n",
      "       and running jobs for the current user are listed. Additional  jobs  and\n",
      "       information  can  be  listed  using options listed below.  Alternately,\n",
      "       specific job ids can be listed on the command line to only  list  those\n",
      "       job IDs.\n",
      "\n",
      "OPTIONS\n",
      "       -a     List  jobs  in  all  states,  including  inactive jobs.  This is\n",
      "              shorthand for --filter=pending,running,inactive.\n",
      "\n",
      "       -A     List jobs of all users. This is shorthand for --user=all.\n",
      "\n",
      "       -n, --no-header\n",
      "              For default output, do not output column headers.\n",
      "\n",
      "       -u, --user=[USERNAME|UID]\n",
      "              List jobs for a specific username or userid. Specify all for all\n",
      "              users.\n",
      "\n",
      "       --name=[JOB NAME]\n",
      "              List jobs with a specific job name.\n",
      "\n",
      "       --queue=[QUEUE]\n",
      "              List jobs in a specific queue.\n",
      "\n",
      "       -c, --count=N\n",
      "              Limit output to N jobs (default 1000)\n",
      "\n",
      "       --since=WHEN\n",
      "              Limit  output  to jobs that have been active since a given time‚Äê\n",
      "              stamp.  In other words, jobs that are  currently  pending,  cur‚Äê\n",
      "              rently  running,  or  became inactive since the given timestamp.\n",
      "              This option implies -a if no other --filter options  are  speci‚Äê\n",
      "              fied.   If  WHEN  begins with - character, then the remainder is\n",
      "              considered to be a an offset in Flux standard duration (RFC 23).\n",
      "              Otherwise,  any  datetime  expression  accepted  by the Python ‚Äê\n",
      "              parsedatetime module is accepted. Examples: \"-6h\", \"-1d\",  \"yes‚Äê\n",
      "              terday\",  \"2021-06-21 6am\", \"last Monday\", etc. It is assumed to\n",
      "              be an error if a timestamp in the future is supplied.\n",
      "\n",
      "       -f, --filter=STATE|RESULT\n",
      "              List jobs with specific job state or result. Multiple states  or\n",
      "              results  can  be listed separated by comma. See JOB STATUS below\n",
      "              for additional information. Defaults to pending,running.\n",
      "\n",
      "       -o, --format=NAME|FORMAT\n",
      "              Specify a named output format NAME  or  a  format  string  using\n",
      "              Python's format syntax. See OUTPUT FORMAT below for field names.\n",
      "              Named formats may be listed via --format=help.  An alternate de‚Äê\n",
      "              fault  format  can be set via the FLUX_JOBS_FORMAT_DEFAULT envi‚Äê\n",
      "              ronment variable.  Additional named formats  may  be  registered\n",
      "              with flux jobs via configuration.  See the CONFIGURATION section\n",
      "              for more details. A configuration snippet for an existing  named\n",
      "              format may be generated with --format=get-config=NAME.\n",
      "\n",
      "       --json Emit  data for selected jobs in JSON format. The data for multi‚Äê\n",
      "              ple matching jobs is contained in a jobs array  in  the  emitted\n",
      "              JSON  object,  unless  a single job was selected by jobid on the\n",
      "              command line, in which case a JSON object representing that  job\n",
      "              is  emitted on success. With --recursive, each job which is also\n",
      "              an instance of Flux will will have any recursively  listed  jobs\n",
      "              in a jobs array, and so on for each sub-child.\n",
      "\n",
      "              Only  the attributes which are available at the time of the flux\n",
      "              jobs query will be present in the returned  JSON  object  for  a\n",
      "              job.  For instance a pending job will not have runtime, waitsta‚Äê\n",
      "              tus or result keys, among others. A missing key should  be  con‚Äê\n",
      "              sidered unavailable.\n",
      "\n",
      "              The --json option is incompatible with --stats and --stats-only,\n",
      "              and any --format is ignored.\n",
      "\n",
      "       --color[=WHEN]\n",
      "              Control output coloring.  The  optional  argument  WHEN  can  be\n",
      "              auto,  never, or always.  If WHEN is omitted, it defaults to al‚Äê\n",
      "              ways.  Otherwise the default is auto.\n",
      "\n",
      "       --stats\n",
      "              Output a summary of job statistics before the  header.   By  de‚Äê\n",
      "              fault  shows  global statistics.  If --queue is specified, shows\n",
      "              statistics for the specified queue.  May be useful  in  conjunc‚Äê\n",
      "              tion with utilities like watch(1), e.g.:\n",
      "\n",
      "                 $ watch -n 2 flux jobs --stats -f running -c 25\n",
      "\n",
      "              will  display a summary of statistics along with the top 25 run‚Äê\n",
      "              ning jobs, updated every 2 seconds.\n",
      "\n",
      "              Note that all job failures, including canceled and timeout jobs,\n",
      "              are collectively counted as \"failed\" in --stats.\n",
      "\n",
      "       --stats-only\n",
      "              Output  a  summary of job statistics and exit.  By default shows\n",
      "              global statistics.  If --queue is  specified,  shows  statistics\n",
      "              for the specified queue.  flux jobs will exit with non-zero exit\n",
      "              status with --stats-only if there are no active jobs.  This  al‚Äê\n",
      "              lows the following loop to work:\n",
      "\n",
      "                 $ while flux jobs --stats-only; do sleep 2; done\n",
      "\n",
      "              All  options other than --queue are ignored when --stats-only is\n",
      "              used.\n",
      "\n",
      "              Note that all job failures, including canceled and timeout jobs,\n",
      "              are collectively counted as \"failed\" in --stats-only.\n",
      "\n",
      "       -R, --recursive\n",
      "              List  jobs recursively. Each child job which is also an instance\n",
      "              of Flux is prefixed by its jobid \"path\" followed by the list  of\n",
      "              jobs,  recursively up to any defined --level. If the --stats op‚Äê\n",
      "              tion is used, then each  child  instance  in  the  hierarchy  is\n",
      "              listed with its stats.\n",
      "\n",
      "       --recurse-all\n",
      "              By  default,  jobs  not  owned by the user running flux jobs are\n",
      "              skipped with --recursive, because normally Flux  instances  only\n",
      "              permit  the  instance  owner  to connect. This option forces the\n",
      "              command to attempt to recurse into the jobs of other users.  Im‚Äê\n",
      "              plies --recursive.\n",
      "\n",
      "       -L, --level=N\n",
      "              With --recursive, stop recursive job listing at level N.  Levels\n",
      "              are counted starting at 0, so flux jobs -R --level=0 is  equiva‚Äê\n",
      "              lent  to  flux jobs without -R, and --level=1 would limit recur‚Äê\n",
      "              sive job listing to child jobs of the current instance.\n",
      "\n",
      "       --threads=N\n",
      "              When flux jobs recursively queries job lists (with  --recursive)\n",
      "              or fetches info for jobs that are also instances (see instance.*\n",
      "              fields), a pool of threads is used to parallelize  the  required\n",
      "              RPCs. Normally, the default number of ThreadPoolExecutor threads\n",
      "              is used, but by  using  the  --threads,  a  specific  number  of\n",
      "              threads can be chosen.\n",
      "\n",
      "JOB STATUS\n",
      "       Jobs  may  be observed to pass through five job states in Flux: DEPEND,\n",
      "       PRIORITY, SCHED, RUN, CLEANUP, and INACTIVE (see Flux  RFC  21).  Under\n",
      "       the  state_single  field  name, these are abbreviated as D, S, P, R, C,\n",
      "       and I respectively. For convenience and clarity, the following  virtual\n",
      "       job  states  also exist: \"pending\", an alias for DEPEND,PRIORITY,SCHED;\n",
      "       \"running\", an alias for RUN,CLEANUP;  \"active\",  an  alias  for  \"pend‚Äê\n",
      "       ing,running\".\n",
      "\n",
      "       After a job has finished and is in the INACTIVE state, it can be marked\n",
      "       with one of the possible results: COMPLETED, FAILED, CANCELED, TIMEOUT.\n",
      "       Under the result_abbrev field name, these are abbreviated as CD, F, CA,\n",
      "       and TO respectively.\n",
      "\n",
      "       The job status is a user friendly mix of both, a job is always  in  one\n",
      "       of  the following statuses: DEPEND, PRIORITY, SCHED, RUN, CLEANUP, COM‚Äê\n",
      "       PLETED, FAILED, CANCELED, or TIMEOUT.  Under  the  status_abbrev  field\n",
      "       name, these are abbreviated as D, P, S, R, C, CD, F, CA, and TO respec‚Äê\n",
      "       tively.\n",
      "\n",
      "OUTPUT FORMAT\n",
      "       The --format option can be used to specify an  output  format  to  flux\n",
      "       jobs using Python's string format syntax. For example, the following is\n",
      "       the format used for the default format:\n",
      "\n",
      "          {id.f58:>12} ?:{queue:<8.8} {username:<8.8} {name:<10.10+} \\\n",
      "          {status_abbrev:>2.2} {ntasks:>6} {nnodes:>6h} \\\n",
      "          {contextual_time!F:>8h} {contextual_info}\n",
      "\n",
      "       If a format field is preceded by the special string ?: this will  cause\n",
      "       the  field to be removed entirely from output if the result would be an\n",
      "       empty string or zero value for all jobs in the listing. E.g.:\n",
      "\n",
      "          {id.f58:>12} ?:{exception.type}\n",
      "\n",
      "       would eliminate the EXCEPTION-TYPE column if no jobs in  the  list  re‚Äê\n",
      "       ceived  an exception. (Thus the job queue is only displayed if at least\n",
      "       one job has a queue assigned in the default format shown above).\n",
      "\n",
      "       As a reminder to the reader, some shells will interpret braces  ({  and\n",
      "       }) in the format string.  They may need to be quoted.\n",
      "\n",
      "       The special presentation type h can be used to convert an empty string,\n",
      "       \"0s\", \"0.0\", \"0:00:00\", or epoch time to a hyphen.  For  example,  nor‚Äê\n",
      "       mally  \"{nodelist}\" would output an empty string if the job has not yet\n",
      "       run.  By specifying, \"{nodelist:h}\", a hyphen would  be  presented  in‚Äê\n",
      "       stead.\n",
      "\n",
      "       The  special suffix + can be used to indicate if a string was truncated\n",
      "       by including a + character when truncation occurs. If both h and +  are\n",
      "       being used, then the + must appear after the h.\n",
      "\n",
      "       Additionally,  the  custom job formatter supports a set of special con‚Äê\n",
      "       version flags. Conversion flags follow the format field and are used to\n",
      "       transform  the value before formatting takes place. Currently, the fol‚Äê\n",
      "       lowing conversion flags are supported by flux jobs:\n",
      "\n",
      "       !D     convert a  timestamp  field  to  ISO8601  date  and  time  (e.g.\n",
      "              2020-01-07T13:31:00).   Defaults  to  empty  string if timestamp\n",
      "              field does not exist or the timestamp is 0 (i.e epoch time).\n",
      "\n",
      "       !d     convert a timestamp to a Python  datetime  object.  This  allows\n",
      "              datetime   specific   format   to   be   used,   e.g.   {t_inac‚Äê\n",
      "              tive!d:%H:%M:%S}. Additionally, width and alignment can be spec‚Äê\n",
      "              ified  after  the  time  format  by  using two colons (::), e.g.\n",
      "              {t_inactive!d:%H:%M:%S::>20}. Returns an empty string (or \"-\" if\n",
      "              the h suffix is used) for an unset timestamp.\n",
      "\n",
      "       !F     convert  a time duration in floating point seconds to Flux Stan‚Äê\n",
      "              dard Duration (FSD)  string  (e.g.  {runtime!F}).   Defaults  to\n",
      "              empty string if field does not exist.\n",
      "\n",
      "       !H     convert  a time duration in floating point seconds to hours:min‚Äê\n",
      "              utes:seconds form (e.g. {runtime!H}).  Defaults to empty  string\n",
      "              if time duration field does not exist.\n",
      "\n",
      "       !P     convert  a  floating point number into a percentage fitting in 5\n",
      "              characters including the \"%\" character. E.g. 0.5  becomes  \"50%\"\n",
      "              0.015 becomes 1.5%, and 0.0005 becomes 0.05% etc.\n",
      "\n",
      "       As a reminder to the reader, some shells will interpret the exclamation\n",
      "       point (!) when using a conversion flag.  The exclamation point may need\n",
      "       to be escaped (\\!).\n",
      "\n",
      "       Annotations  can be retrieved via the annotations field name.  Specific\n",
      "       keys and sub-object keys can be retrieved separated by a period  (\".\").\n",
      "       For example, if the scheduler has annotated the job with a reason pend‚Äê\n",
      "       ing status, it can be  retrieved  via  \"{annotations.sched.reason_pend‚Äê\n",
      "       ing}\".\n",
      "\n",
      "       As a convenience, the field names sched and user can be used as substi‚Äê\n",
      "       tutions for annotations.sched and  annotations.user.   For  example,  a\n",
      "       reason pending status can be retrieved via \"{sched.reason_pending}\".\n",
      "\n",
      "       The field names that can be specified are:\n",
      "\n",
      "       id     job ID\n",
      "\n",
      "       id.f58 job ID in RFC 19 F58 (base58) encoding\n",
      "\n",
      "       id.f58plain\n",
      "              job ID in RFC 19 F58 encoding with ascii f\n",
      "\n",
      "       id.dec job ID in decimal representation\n",
      "\n",
      "       id.hex job ID in 0x prefix hexadecimal representation\n",
      "\n",
      "       id.dothex\n",
      "              job ID in dotted hexadecimal representation (xx.xx.xx.xx)\n",
      "\n",
      "       id.words\n",
      "              job ID in mnemonic encoding\n",
      "\n",
      "       id.emoji\n",
      "              job ID in emoji encoding\n",
      "\n",
      "       userid job submitter's userid\n",
      "\n",
      "       username\n",
      "              job submitter's username\n",
      "\n",
      "       urgency\n",
      "              job urgency\n",
      "\n",
      "       priority\n",
      "              job priority\n",
      "\n",
      "       dependencies\n",
      "              list of any currently outstanding job dependencies\n",
      "\n",
      "       status job status (DEPEND, SCHED, RUN, CLEANUP, COMPLETED, FAILED, CAN‚Äê\n",
      "              CELED, or TIMEOUT)\n",
      "\n",
      "       status_abbrev\n",
      "              status but in a max 2 character abbreviation\n",
      "\n",
      "       status_emoji\n",
      "              status but an appropriate emoji instead of job state / result\n",
      "\n",
      "       name   job name\n",
      "\n",
      "       cwd    job current working directory\n",
      "\n",
      "       queue  job queue\n",
      "\n",
      "       project\n",
      "              job accounting project\n",
      "\n",
      "       bank   job accounting bank\n",
      "\n",
      "       ntasks job task count\n",
      "\n",
      "       ncores job core count\n",
      "\n",
      "       duration\n",
      "              job duration in seconds\n",
      "\n",
      "       nnodes job node count (if job ran / is running), empty string otherwise\n",
      "\n",
      "       ranks  job ranks (if job ran / is running), empty string otherwise\n",
      "\n",
      "       nodelist\n",
      "              job nodelist (if job ran / is running), empty string otherwise\n",
      "\n",
      "       state  job state (DEPEND, SCHED, RUN, CLEANUP, INACTIVE)\n",
      "\n",
      "       state_single\n",
      "              job state as a single character\n",
      "\n",
      "       state_emoji\n",
      "              job state but an appropriate emoji  instead  of  DEPEND,  SCHED,\n",
      "              RUN, CLEANUP, or INACTIVE\n",
      "\n",
      "       result job  result  if  job  is  inactive (COMPLETED, FAILED, CANCELED,\n",
      "              TIMEOUT), empty string otherwise\n",
      "\n",
      "       result_abbrev\n",
      "              result but in a max 2 character abbreviation\n",
      "\n",
      "       result_emoji\n",
      "              result but an appropriate emoji instead  of  COMPLETED,  FAILED,\n",
      "              CANCELED, or TIMEOUT\n",
      "\n",
      "       success\n",
      "              True of False if job completed successfully, empty string other‚Äê\n",
      "              wise\n",
      "\n",
      "       waitstatus\n",
      "              The raw status of the job as returned by waitpid(2) if  the  job\n",
      "              exited, otherwise an empty string. Note: waitstatus is the maxi‚Äê\n",
      "              mum wait status returned by all job shells in a job,  which  may\n",
      "              not  necessarily indicate the highest task wait status. (The job\n",
      "              shell exits with the maximum task exit  status,  unless  a  task\n",
      "              died  due  to  a  signal,  in  which  case  the shell exits with\n",
      "              128+signo)\n",
      "\n",
      "       returncode\n",
      "              The job return code if the job has exited, or an empty string if\n",
      "              the job is still active. The return code of a job is the highest\n",
      "              job shell exit code, or negative signal number if the job  shell\n",
      "              was  terminated  by  a signal. If the job was canceled before it\n",
      "              started, then the returncode is set to the special value -128.\n",
      "\n",
      "       exception.occurred\n",
      "              True of False if job had an exception, empty string otherwise\n",
      "\n",
      "       exception.severity\n",
      "              If exception.occurred True, the highest severity,  empty  string\n",
      "              otherwise\n",
      "\n",
      "       exception.type\n",
      "              If exception.occurred True, the highest severity exception type,\n",
      "              empty string otherwise\n",
      "\n",
      "       exception.note\n",
      "              If exception.occurred True, the highest severity exception note,\n",
      "              empty string otherwise\n",
      "\n",
      "       t_submit\n",
      "              time job was submitted\n",
      "\n",
      "       t_depend\n",
      "              time job entered depend state\n",
      "\n",
      "       t_run  time job entered run state\n",
      "\n",
      "       t_cleanup\n",
      "              time job entered cleanup state\n",
      "\n",
      "       t_inactive\n",
      "              time job entered inactive state\n",
      "\n",
      "       runtime\n",
      "              job runtime\n",
      "\n",
      "       expiration\n",
      "              time at which job allocation was marked to expire\n",
      "\n",
      "       t_remaining\n",
      "              If job is running, amount of time remaining before expiration\n",
      "\n",
      "       annotations\n",
      "              annotations metadata, use \".\" to get specific keys\n",
      "\n",
      "       sched  short hand for annotations.sched\n",
      "\n",
      "       user   short hand for annotations.user\n",
      "\n",
      "       Field names which are specific to jobs which are also instances of Flux\n",
      "       include:\n",
      "\n",
      "       instance.stats\n",
      "              a short string describing current job  statistics  for  the  in‚Äê\n",
      "              stance  of  the  form  PD:{pending}  R:{running} CD:{successful}\n",
      "              F:{failed}\n",
      "\n",
      "       instance.stats.total\n",
      "              total number of jobs in any state in the instance.\n",
      "\n",
      "       instance.utilization\n",
      "              number of cores currently allocated divided by the total  number\n",
      "              of  cores.  Can be formatted as a percentage with !P, e.g.  {in‚Äê\n",
      "              stance.utilization!P:>4}.\n",
      "\n",
      "       instance.gpu_utilization\n",
      "              same as instance.utilization but for gpu resources\n",
      "\n",
      "       instance.progress\n",
      "              number of inactive jobs divided by the  total  number  of  jobs.\n",
      "              Can be formatted as a percentage with {instance.progress!P:>4}\n",
      "\n",
      "       instance.resources.<state>.{ncores,ngpus}\n",
      "              number  of  cores,  gpus in state state, where state can be all,\n",
      "              up,   down,   allocated,   or    free,    e.g.     {instance.re‚Äê\n",
      "              sources.all.ncores}\n",
      "\n",
      "       The  following fields may return different information depending on the\n",
      "       state of the job or other context:\n",
      "\n",
      "       contextual_info\n",
      "              Returns selected information based on the job's  current  state.\n",
      "              If  the  job is in PRIORITY state, then the string priority-wait\n",
      "              is returned, if the job is in DEPEND state, then a list of  out‚Äê\n",
      "              standing  dependencies is returned, if the job is in SCHED state\n",
      "              then an estimated time the job will  run  is  returned  (if  the\n",
      "              scheduler  supports it). Otherwise, the assigned nodelist is re‚Äê\n",
      "              turned (if resources were assigned).\n",
      "\n",
      "       contextual_info\n",
      "              Returns the job runtime for jobs in RUN state or  later,  other‚Äê\n",
      "              wise the job duration (if set) is returned.\n",
      "\n",
      "       inactive_reason\n",
      "              If  the  job  is inactive, returns the reason that the job is no\n",
      "              longer active.  Generally speaking, will output  \"Exit\",  \"Time‚Äê\n",
      "              out\", \"Canceled\", or signal.  If available, other contextual in‚Äê\n",
      "              formation will also be provided such as the exit  returncode  or\n",
      "              cancellation message.\n",
      "\n",
      "CONFIGURATION\n",
      "       The  flux jobs command supports registration of named output formats in\n",
      "       configuration  files.  The  command  loads  configuration  files   from\n",
      "       flux-jobs.EXT  from  the  following paths in order of increasing prece‚Äê\n",
      "       dence:\n",
      "\n",
      "          ‚Ä¢ $XDG_CONFIG_DIRS/flux or /etc/xdg/flux if XDG_CONFIG_DIRS  is  not\n",
      "            set.  Note that XDG_CONFIG_DIRS is traversed in reverse order such\n",
      "            that entries first in the colon separated path are highest  prior‚Äê\n",
      "            ity.\n",
      "\n",
      "          ‚Ä¢ $XDG_CONFIG_HOME/flux  or $HOME/.config/flux if XDG_CONFIG_HOME is\n",
      "            not set\n",
      "\n",
      "       where EXT can be one of toml, yaml, or json.\n",
      "\n",
      "       If there are multiple flux-jobs.* files found in a directory, then they\n",
      "       are loaded in lexical order (i.e. .json first, then .toml, then .yaml)\n",
      "\n",
      "       Named  formats  are  registered in a formats table or dictionary with a\n",
      "       key per format pointing to a table or dictionary with the keys:\n",
      "\n",
      "       format (required) The format string\n",
      "\n",
      "       description\n",
      "              (optional) A short description of the  named  format,  displayed\n",
      "              with flux jobs --format=help\n",
      "\n",
      "       If  a  format  name is specified in more than one config file, then the\n",
      "       last one loaded is used. Due to the order that flux jobs  loads  config\n",
      "       files, this allows user configuration to override system configuration.\n",
      "       It is an error to override any internally defined formats (such as  de‚Äê\n",
      "       fault).\n",
      "\n",
      "       If a format name or string is not specified on the command line the in‚Äê\n",
      "       ternally defined format default is used.\n",
      "\n",
      "       Example:\n",
      "\n",
      "          # $HOME/.config/flux/flux-jobs.toml\n",
      "\n",
      "          [formats.myformat]\n",
      "          description = \"My useful format\"\n",
      "          format = \"\"\"\\\n",
      "          {id.f58:>12} {name:>8.8} {t_submit!D:<19} \\\n",
      "          {t_run!D:<19} {t_remaining!F}\\\n",
      "          \"\"\"\n",
      "\n",
      "       It may be helpful to start with an existing named format by  using  the\n",
      "       --format=get-config=NAME option, e.g.:\n",
      "\n",
      "          $ flux jobs --format=get-config=default >> ~/.config/flux/flux-jobs.toml\n",
      "\n",
      "       Be  sure to change the name of the format string from default. It is an\n",
      "       error to redefine the default format string.\n",
      "\n",
      "EXAMPLES\n",
      "       The default output of flux jobs will list the pending and running  jobs\n",
      "       of the current user.  It is equivalent to:\n",
      "\n",
      "          $ flux jobs --filter=pending,running\n",
      "\n",
      "       To  list  all pending, running, and inactive jobs, of the current user,\n",
      "       you can use --filter option or the -a option:\n",
      "\n",
      "          $ flux jobs -a\n",
      "\n",
      "          OR\n",
      "\n",
      "          $ flux jobs --filter=pending,running,inactive\n",
      "\n",
      "       To alter which user's jobs are listed, specify the user with --user:\n",
      "\n",
      "          $ flux jobs --user=flux\n",
      "\n",
      "       Jobs that have finished may be filtered further by specifying  if  they\n",
      "       have  completed,  failed, or were canceled.  For example, the following\n",
      "       will list the jobs that have failed or were canceled:\n",
      "\n",
      "          $ flux jobs --filter=failed,canceled\n",
      "\n",
      "       The --format option can be used to alter the output  format  or  output\n",
      "       additional  information.   For  example, the following would output all\n",
      "       jobids for the user in decimal form, and  output  any  annotations  the\n",
      "       scheduler attached to each job:\n",
      "\n",
      "          $ flux jobs -a --format=\"{id} {annotations.sched}\"\n",
      "\n",
      "       The  following  would output the job id and exception information, so a\n",
      "       user can learn why a job failed.\n",
      "\n",
      "          $ flux jobs --filter=failed --format=\"{id} {exception.type} {exception.note}\"\n",
      "\n",
      "RESOURCES\n",
      "       Flux: http://flux-framework.org\n",
      "\n",
      "       Flux RFC: https://flux-framework.readthedocs.io/projects/flux-rfc\n",
      "\n",
      "SEE ALSO\n",
      "       flux-pstree(1)\n",
      "\n",
      "AUTHOR\n",
      "       This page is maintained by the Flux community.\n",
      "\n",
      "COPYRIGHT\n",
      "       Copyright 2014 Lawrence Livermore National Security, LLC and  Flux  de‚Äê\n",
      "       velopers.\n",
      "\n",
      "       SPDX-License-Identifier: LGPL-3.0\n",
      "\n",
      "                                 Jun 06, 2024                     FLUX-JOBS(1)\n"
     ]
    }
   ],
   "source": [
    "!flux help jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e435d6-0927-4966-a4d7-47a128c94158",
   "metadata": {
    "tags": []
   },
   "source": [
    "### What does the terminal prompt mean?\n",
    "For cases when you need a terminal, we will <button data-commandLinker-command=\"terminal:open\" data-name=\"flux\" href=\"#\">provide you with a button</button>! However, you can also select `File -> New -> Terminal` to open one on the fly. Let's next talk about flux instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec052119",
   "metadata": {},
   "source": [
    "## Flux Resources\n",
    "\n",
    "When you are interacting with Flux, you will commonly want to know what resources are available to you. Flux uses [hwloc](https://github.com/open-mpi/hwloc) to detect the resources on each node and then to populate its resource graph.\n",
    "\n",
    "You can access the topology information that Flux collects with the `flux resource` subcommand. Let's run `flux resource list` to see the resources available to us in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scenic-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STATE NNODES   NCORES    NGPUS NODELIST\n",
      "      free      4       38        0 8660c254a8e[5,5,5,5]\n",
      " allocated      1        2        0 8660c254a8e5\n",
      "      down      0        0        0 \n"
     ]
    }
   ],
   "source": [
    "!flux resource list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086e47e",
   "metadata": {},
   "source": [
    "Flux can also bootstrap its resource graph based on static input files, like in the case of a multi-user system instance setup by site administrators.  [More information on Flux's static resource configuration files](https://flux-framework.readthedocs.io/projects/flux-core/en/latest/guide/admin.html#configuration).  Flux provides a more standard interface to listing available resources that works regardless of the resource input source: `flux resource`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prime-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STATE UP NNODES NODELIST\n",
      "     avail \u001b[01;32m ‚úî\u001b[0;0m      4 8660c254a8e[5,5,5,5]\n"
     ]
    }
   ],
   "source": [
    "# To view status of resources\n",
    "!flux resource status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6603d7f-dd45-4743-9efb-bf65ba7e2f22",
   "metadata": {},
   "source": [
    "It might also be the case that you need to see queues. Here is how to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7fbe877-c0bf-4296-a20b-21809caa72d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DEFAULTTIME  TIMELIMIT     NNODES     NCORES      NGPUS\n",
      "         inf        inf      0-inf      0-inf      0-inf\n"
     ]
    }
   ],
   "source": [
    "!flux queue list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2d6af-43fa-490e-88e9-10f13e660125",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "# Flux Commands \n",
    "\n",
    "Here are how Flux commands map to a scheduler you are likely familiar with, Slurm. A larger table with similar mappings for LSF, Moab, and Slurm can be [viewed here](https://hpc.llnl.gov/banks-jobs/running-jobs/batch-system-cross-reference-guides). For submitting jobs, you can use the `flux` `submit`, `run`, `bulksubmit`, `batch`, and `alloc` commands.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Operation</th>\n",
    "        <th>Slurm</th>\n",
    "        <th>Flux</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>One-off run of a single job (blocking)</td>\n",
    "        <td><code>srun</code></td>\n",
    "        <td><code>flux run</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>One-off run of a single job (interactive)</td>\n",
    "        <td><code>srun --pty</code></td>\n",
    "        <td><code>flux run -o pty.interactive</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>One-off run of a single job (not blocking)</td>\n",
    "        <td><code>NA</code></td>\n",
    "        <td><code>flux submit</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bulk submission of jobs (not blocking)</td>\n",
    "        <td><code>NA</code></td>\n",
    "        <td><code>flux bulksubmit</code></td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td>Watching jobs</td>\n",
    "        <td><code>NA</code></td>\n",
    "        <td><code>flux watch</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Querying the status of jobs</td>\n",
    "        <td><code>squeue</code>/<code>scontrol show job <i>job_id</i></code></td>\n",
    "        <td><code>flux jobs</code>/<code>flux job info <i>job_id</i></code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Canceling running jobs</td>\n",
    "        <td><code>scancel</code></td>\n",
    "        <td><code>flux cancel</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Allocation for an interactive instance</td>\n",
    "        <td><code>salloc</code></td>\n",
    "        <td><code>flux alloc</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Submitting batch jobs</td>\n",
    "        <td><code>sbatch</code></td>\n",
    "        <td><code>flux batch</code></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac798095",
   "metadata": {},
   "source": [
    "## flux run\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> Running a single job (blocking)\n",
    "</div>\n",
    "\n",
    "The `flux run` command submits a job to Flux (similar to `flux submit`) but then attaches to the job with `flux job attach`, printing the job's stdout/stderr to the terminal and exiting with the same exit code as the job. It's basically doing an interactive submit, because you will be able to watch the output in your terminal, and it will block your terminal until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52d26496-dd1f-44f7-bb10-8a9b4b8c9c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749a39b51885\n"
     ]
    }
   ],
   "source": [
    "!flux run hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53357a9d-11d8-4c2d-87d8-c30ae38d01ba",
   "metadata": {},
   "source": [
    "The output from the previous command is the hostname (a container ID string in this case). If the job exits with a non-zero exit code this will be reported by `flux job attach` (occurs implicitly with `flux run`). For example, execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa40cb98-a138-4771-a7ef-f1860dddf7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flux-job: task(s) exited with exit code 1\n"
     ]
    }
   ],
   "source": [
    "!flux run /bin/false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b5c3f-e24a-45a8-a10c-e10bfdbb7b87",
   "metadata": {},
   "source": [
    "A job submitted with `run` can be canceled with two rapid `Cltr-C`s in succession, or a user can detach from the job with `Ctrl-C Ctrl-Z`. The user can then re-attach to the job by using `flux job attach JOBID`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5213d",
   "metadata": {},
   "source": [
    "`flux submit` and `flux run` also support many other useful flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02032748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 8660c254a8e5\n",
      "2: 8660c254a8e5\n",
      "1: 8660c254a8e5\n",
      "0: 8660c254a8e5\n"
     ]
    }
   ],
   "source": [
    "!flux run -n4 --label-io --time-limit=5s --env-remove=LD_LIBRARY_PATH hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f52bb357-a7ce-458d-9c3f-4d664eca4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this help command if you want to see all the flags for flux run\n",
    "# !flux run --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09708a-74a1-4e61-b678-cb337b7df435",
   "metadata": {},
   "source": [
    "## flux submit\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> Running a single job (not blocking)\n",
    "</div>\n",
    "\n",
    "\n",
    "The `flux submit` command submits a job to Flux and prints out the jobid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2bddee-f454-4674-80d4-4a39c5f1bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: flux submit [OPTIONS...] COMMAND [ARGS...]\n",
      "\n",
      "enqueue a job\n",
      "\n",
      "positional arguments:\n",
      "  command                     Job command and arguments\n",
      "\n",
      "options:\n",
      "  -h, --help                  show this help message and exit\n",
      "  -q, --queue=NAME            Submit a job to a specific named queue\n",
      "  -t, --time-limit=MIN|FSD    Time limit in minutes when no units provided,\n",
      "                              otherwise in Flux standard duration, e.g. 30s,\n",
      "                              2d, 1.5h\n",
      "      --urgency=N             Set job urgency (0-31), hold=0, default=16,\n",
      "                              expedite=31\n"
     ]
    }
   ],
   "source": [
    "# Let's peek at the help for flux submit!\n",
    "!flux submit --help | head -n 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5e7d41-1d8d-426c-8198-0ad4a57e7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆íckWM1ZXM\n"
     ]
    }
   ],
   "source": [
    "!flux submit hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809292e5-3f24-4528-916f-8733d065de47",
   "metadata": {},
   "source": [
    "But how does one get output? To quickly see output (which will block the terminal if the job is still running) after a submit, you can do:\n",
    "\n",
    "```bash\n",
    "flux job attach $(flux job last)\n",
    "```\n",
    "\n",
    "To provide a custom path to an output or error file, you can provide `--out` and `--err`, respectively. Let's try those both now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a4da7f-2b84-4c67-9da1-02435005d392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆íckWM1ZXM\n",
      "749a39b51885\n"
     ]
    }
   ],
   "source": [
    "# What was the last job id again?\n",
    "! flux job last\n",
    "\n",
    "# Attach to the last job id that was submitted (will block if still running and stream output)\n",
    "! flux job attach $(flux job last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a851d3-0179-4e5e-9e20-93bc11b5056f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆ífeTb2bBm\n",
      "Did a polar bear with a soft drink write this...?! üêª‚Äç‚ùÑÔ∏èü•§Ô∏èüòéÔ∏è \n"
     ]
    }
   ],
   "source": [
    "# Now let's submit another one, and give it the same output and error file\n",
    "! flux submit --out /tmp/hola-cola.txt --err /tmp/hola-cola.txt echo \"Did a polar bear with a soft drink write this...?! üêª‚Äç‚ùÑÔ∏èü•§Ô∏èüòéÔ∏è \"\n",
    "\n",
    "# Take a look!\n",
    "! cat /tmp/hola-cola.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4c25e-3ca8-4277-bb70-a0e94bcd223b",
   "metadata": {},
   "source": [
    "`submit` supports common options like `--nnodes`, `--ntasks`, and `--cores-per-task`. There are short option equivalents (`-N`, `-n`, and `-c`, respectively) of these options as well. `--cores-per-task=1` is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "571d8c3d-b24a-415e-b9ac-f58b99a7e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3VqVSHr7q\n"
     ]
    }
   ],
   "source": [
    "!flux submit -N1 -n2 sleep inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9ed6c",
   "metadata": {},
   "source": [
    "## flux bulksubmit\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> Submitting jobs in bulk (not blocking)\n",
    "</div>\n",
    "\n",
    "The `flux bulksubmit` command enqueues jobs based on a set of inputs which are substituted on the command line, similar to `xargs` and the GNU `parallel` utility, except the jobs have access to the resources of an entire Flux instance instead of only the local system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e82702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3VqabmM3V\n",
      "∆í3VqabmM3W\n",
      "∆í3VqadFLKq\n",
      "foo\n",
      "bar\n",
      "baz\n"
     ]
    }
   ],
   "source": [
    "!flux bulksubmit --watch --wait echo {} ::: foo bar baz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba88b4-538d-4eb6-baf9-735581b4d717",
   "metadata": {},
   "source": [
    "### carbon copy\n",
    "\n",
    "The `--cc` option (akin to \"carbon copy\") to `submit` makes repeated submission even easier via, `flux submit --cc=IDSET`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea1962b-1831-4bd2-8dab-c61fd710df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3VqhAnAU7\n",
      "∆í3VqhAnAU8\n",
      "∆í3VqhAnAU9\n",
      "∆í3VqhAnAUA\n"
     ]
    }
   ],
   "source": [
    "!flux submit --cc=1-4 hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca3706-8bb4-4fd6-a37c-e6135fb05604",
   "metadata": {},
   "source": [
    "Try it in the <button data-commandLinker-command=\"terminal:open\" data-name=\"flux\" href=\"#\">JupyterLab terminal</button> with a progress bar and jobs/s rate report: `flux submit --cc=1-100 --watch --progress --jps hostname`\n",
    "\n",
    "Note that `--wait` is implied by `--watch`, meaning that when you are watching jobs, you are also waiting for them to finish. Here are some other carbon copy commands that are useful to try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e93d8e3-9342-4edd-b262-757355ddfe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3Vqogq1L3\n",
      "∆í3Vqogq1L4\n"
     ]
    }
   ],
   "source": [
    "# Use flux carbon copy to submit identical jobs with different inputs\n",
    "!flux submit --cc=\"1-2\" echo \"Hello I am job {cc}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a18ff-8d6a-47e9-a164-931ed1275ef4",
   "metadata": {},
   "source": [
    "Here are some \"carbon copy\" jobs to try in the <button data-commandLinker-command=\"terminal:open\" data-name=\"flux\" href=\"#\">JupyterLab terminal</button>:\n",
    "\n",
    "```bash\n",
    "# Use flux carbon copy to submit identical jobs with different inputs\n",
    "flux submit --cc=\"1-10\" echo \"Hello I am job {cc}\"\n",
    "\n",
    "# Submits scripts myscript1.sh through myscript10.sh\n",
    "flux submit --cc=0-6 flux-workflow-examples/bulksubmit/{cc}.sh\n",
    "\n",
    "# Bypass the key value store and write output to file with jobid\n",
    "flux submit --cc=1-10 --output=job-{{id}}.out echo \"This is job {cc}\"\n",
    "\n",
    "# Use carbon copy to submit identical jobs with different inputs\n",
    "flux bulksubmit --dry-run --cc={1} echo {0} ::: a b c ::: 0-1 0-3 0-7\n",
    "```\n",
    "\n",
    "Of course, Flux can launch more than just single-node, single-core jobs.  We can submit multiple heterogeneous jobs and Flux will co-schedule the jobs while also ensuring no oversubscription of resources (e.g., cores). Let's run the second example here, and add a clever trick to ask for output as we submit the jobs. This is a fun one, I promise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f089be5-6d32-40db-b9e9-328e5200b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time... üìóÔ∏è\n",
      "There was a little duck ü¶ÜÔ∏è\n",
      "Her name was pizzaquack üçïÔ∏è\n",
      "She was very fond of cheese üßÄÔ∏è\n",
      "And running Flux üåÄÔ∏è\n",
      "And so she ran Flux, while she ate her cheese üòãÔ∏è\n",
      "And was so happy! The end. üåàÔ∏è\n"
     ]
    }
   ],
   "source": [
    "! for jobid in $(flux submit --cc=0-6 /bin/bash flux-workflow-examples/bulksubmit/{cc}.sh); do flux job attach ${jobid}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3623b2-ca25-4d42-8e43-0c8e038464b4",
   "metadata": {},
   "source": [
    "Note: in this tutorial, we cannot assume that the host you are running on has multiple cores, thus the examples below only vary the number of nodes per job.  Varying the `cores-per-task` is also possible on Flux when the underlying hardware supports it (e.g., a multi-core node). Let's run the middle example - it's a fun one, I promise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "brazilian-former",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3VqtrJWFh\n",
      "∆í3VqzNXq8B\n"
     ]
    }
   ],
   "source": [
    "!flux submit --nodes=2 --ntasks=2 --cores-per-task=1 --job-name simulation sleep inf\n",
    "!flux submit --nodes=1 --ntasks=1 --cores-per-task=1 --job-name analysis sleep inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f446c-b2e8-40d8-b6bd-eb6b9dba3c71",
   "metadata": {},
   "source": [
    "## flux watch\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> üëÄÔ∏è Watching jobs\n",
    "</div>\n",
    "\n",
    "Wouldn't it be cool to submit a job and then watch it? Well, yeah! We can do this now with flux watch. Let's run a fun example, and then watch the output. We have sleeps in here interspersed with echos only to show you the live action! ü•ûÔ∏è\n",
    "Also note a nice trick - you can always use `flux job last` to get the last JOBID.\n",
    "Here is an example (not runnable, as notebooks don't support environment variables) for getting and saving a job id:\n",
    "\n",
    "```bash\n",
    "flux submit hostname\n",
    "JOBID=$(flux job last)\n",
    "```\n",
    "\n",
    "And then you could use the variable `$JOBID` in your subsequent script or interactions with Flux! So what makes `flux watch` different from `flux job attach`? Aside from the fact that `flux watch` is read-only, `flux watch` can watch many (or even all (`flux watch --all`) jobs at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad231c2-4cdb-4d18-afc2-7cb3a74759c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3Vr6FWywV\n",
      "25 chocolate chip pancakes on the table... 25 chocolate chip pancakes! ü•ûÔ∏è\n",
      "Eat a stack, for a snack, 15 chocolate chip pancakes on the table! ü•ÑÔ∏è\n",
      "15 chocolate chip pancakes on the table... 15 chocolate chip pancakes! ü•ûÔ∏è\n",
      "Throw a stack... it makes a smack! 15 chocolate chip pancakes on the wall! ü•ûÔ∏è\n",
      "You got some cleaning to do üßΩÔ∏è\n"
     ]
    }
   ],
   "source": [
    "!flux submit ./flux-workflow-examples/job-watch/job-watch.sh\n",
    "!flux watch $(flux job last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c2af2",
   "metadata": {},
   "source": [
    "## flux jobs\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> Querying the status of jobs\n",
    "</div>\n",
    "\n",
    "We can now list the jobs in the queue with `flux jobs` and we should see both jobs that we just submitted. Jobs that are instances are colored blue in output, red jobs are failed jobs, and green jobs are those that completed successfully. Note that the JupyterLab notebook may not display these colors. You will be able to see them in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "institutional-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       JOBID USER     NAME       ST NTASKS NNODES     TIME INFO\n",
      "  ∆í3VqzNXq8B jovyan   analysis    R      1      1   10.49s 8660c254a8e5\n",
      "  ∆í3VqtrJWFh jovyan   simulation  R      2      2   10.71s 8660c254a8e[5,5]\n",
      "  ∆í3VqVSHr7q jovyan   sleep       R      2      1   11.62s 8660c254a8e5\n",
      "    ∆ínyvM4Nb jovyan   sleep       R      2      1   5.269h 8660c254a8e5\n"
     ]
    }
   ],
   "source": [
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7228e0e-557c-455c-9903-073ef40a56a5",
   "metadata": {},
   "source": [
    "You might also want to see \"all\" jobs with `-a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70dd1459-e21f-46b5-84a4-bd165cf97f4b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       JOBID USER     NAME       ST NTASKS NNODES     TIME INFO\n",
      "  ∆í3VqzNXq8B jovyan   analysis    R      1      1   10.71s 8660c254a8e5\n",
      "  ∆í3VqtrJWFh jovyan   simulation  R      2      2   10.92s 8660c254a8e[5,5]\n",
      "  ∆í3VqVSHr7q jovyan   sleep       R      2      1   11.84s 8660c254a8e5\n",
      "    ∆ínyvM4Nb jovyan   sleep       R      2      1   5.269h 8660c254a8e5\n",
      "\u001b[01;32m  ∆í3Vr6FWywV jovyan   job-watch+ CD      1      1   10.03s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3Vqogq1L3 jovyan   echo       CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3Vqogq1L4 jovyan   echo       CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAUA jovyan   hostname   CD      1      1   0.060s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAU9 jovyan   hostname   CD      1      1   0.050s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAU8 jovyan   hostname   CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAU7 jovyan   hostname   CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqadFLKq jovyan   echo       CD      1      1   0.025s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqabmM3W jovyan   echo       CD      1      1   0.025s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqabmM3V jovyan   echo       CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqNqo3Qs jovyan   hostname   CD      1      1   0.016s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqBbUVR9 jovyan   hostname   CD      4      1   0.017s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í3Vq5LFXNf jovyan   false       F      1      1   0.037s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VpyWEM83 jovyan   hostname   CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VPB8ZEqV jovyan   echo       CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3V7Tprhqh jovyan   echo       CD      1      1   0.060s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3V35oKmEo jovyan   echo       CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2mzETcgvB jovyan   echo       CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2mnMLCXPd jovyan   echo       CD      1      1   0.036s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2mfhe5NCX jovyan   echo       CD      1      1   0.036s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FE jovyan   sleep      CD      1      1   0.077s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y2 jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y8 jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xx jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y5 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y7 jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y1 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xs jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xt jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y3 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gd jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y4 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FF jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FG jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xv jovyan   sleep      CD      1      1   0.117s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FH jovyan   sleep      CD      1      1   0.073s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xu jovyan   sleep      CD      1      1   0.117s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FD jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xw jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y6 jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xz jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gc jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gb jovyan   sleep      CD      1      1   0.087s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xy jovyan   sleep      CD      1      1   0.086s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gX jovyan   sleep      CD      1      1   0.101s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QK jovyan   sleep      CD      1      1   0.109s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QJ jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QD jovyan   sleep      CD      1      1   0.111s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QG jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gY jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266ga jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gZ jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QL jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QH jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QF jovyan   sleep      CD      1      1   0.077s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QE jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QC jovyan   sleep      CD      1      1   0.062s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887z jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887y jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QB jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887w jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887x jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887v jovyan   sleep      CD      1      1   0.088s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZN jovyan   sleep      CD      1      1   0.091s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887s jovyan   sleep      CD      1      1   0.088s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887u jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEwe8qV jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZL jovyan   sleep      CD      1      1   0.077s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887r jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887t jovyan   sleep      CD      1      1   0.073s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZM jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887q jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEwe8qW jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZG jovyan   sleep      CD      1      1   0.082s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZF jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9Z9 jovyan   sleep      CD      1      1   0.094s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZE jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZB jovyan   sleep      CD      1      1   0.094s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZA jovyan   sleep      CD      1      1   0.094s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZH jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZK jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZJ jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH6 jovyan   sleep      CD      1      1   0.081s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZD jovyan   sleep      CD      1      1   0.069s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZC jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH3 jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH5 jovyan   sleep      CD      1      1   0.072s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH2 jovyan   sleep      CD      1      1   0.064s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH1 jovyan   sleep      CD      1      1   0.067s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGw jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGx jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH4 jovyan   sleep      CD      1      1   0.063s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGz jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGv jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzd jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGy jovyan   sleep      CD      1      1   0.058s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGt jovyan   sleep      CD      1      1   0.059s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGu jovyan   sleep      CD      1      1   0.058s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzb jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzc jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAza jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAze jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGq jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGr jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGp jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGs jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzY jovyan   sleep      CD      1      1   0.088s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzZ jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzf jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzi jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGo jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzg jovyan   sleep      CD      1      1   0.080s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzj jovyan   sleep      CD      1      1   0.071s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzW jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzX jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiM jovyan   sleep      CD      1      1   0.112s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiJ jovyan   sleep      CD      1      1   0.111s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzh jovyan   sleep      CD      1      1   0.062s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiK jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiL jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiH jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzT jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzV jovyan   sleep      CD      1      1   0.092s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzU jovyan   sleep      CD      1      1   0.092s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiG jovyan   sleep      CD      1      1   0.087s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiA jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiF jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiD jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiE jovyan   sleep      CD      1      1   0.070s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRy jovyan   sleep      CD      1      1   0.069s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBi9 jovyan   sleep      CD      1      1   0.068s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBi8 jovyan   sleep      CD      1      1   0.066s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiB jovyan   sleep      CD      1      1   0.065s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiC jovyan   sleep      CD      1      1   0.064s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBi7 jovyan   sleep      CD      1      1   0.064s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRu jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRw jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRt jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRx jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRr jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRv jovyan   sleep      CD      1      1   0.048s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRs jovyan   sleep      CD      1      1   0.048s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRq jovyan   sleep      CD      1      1   0.059s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRp jovyan   sleep      CD      1      1   0.114s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9d jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9Y jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9e jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9b jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9W jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRm jovyan   sleep      CD      1      1   0.122s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9f jovyan   sleep      CD      1      1   0.122s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9a jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9Z jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9X jovyan   sleep      CD      1      1   0.122s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDsC jovyan   sleep      CD      1      1   0.100s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9c jovyan   sleep      CD      1      1   0.099s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9U jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9T jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9R jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRn jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9S jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9V jovyan   sleep      CD      1      1   0.091s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRo jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvN jovyan   sleep      CD      1      1   0.105s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs5 jovyan   sleep      CD      1      1   0.105s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs8 jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvQ jovyan   sleep      CD      1      1   0.105s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs9 jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs7 jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs6 jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvP jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvR jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvS jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDsB jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvK jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvJ jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvT jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvM jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvL jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvU jovyan   sleep      CD      1      1   0.071s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDsA jovyan   sleep      CD      1      1   0.069s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvH jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe7 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvG jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe4 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe6 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvF jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe5 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe8 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMm jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMg jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMf jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMi jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdy jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdv jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMh jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe2 jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe3 jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdw jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdz jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe9 jovyan   sleep      CD      1      1   0.191s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMp jovyan   sleep      CD      1      1   0.175s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMj jovyan   sleep      CD      1      1   0.173s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdx jovyan   sleep      CD      1      1   0.174s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMq jovyan   sleep      CD      1      1   0.173s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe1 jovyan   sleep      CD      1      1   0.174s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMn jovyan   sleep      CD      1      1   0.171s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMZ jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5G jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5F jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5E jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdu jovyan   sleep      CD      1      1   0.166s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMo jovyan   sleep      CD      1      1   0.167s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMk jovyan   sleep      CD      1      1   0.166s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMd jovyan   sleep      CD      1      1   0.165s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMb jovyan   sleep      CD      1      1   0.163s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMe jovyan   sleep      CD      1      1   0.162s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMa jovyan   sleep      CD      1      1   0.162s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMc jovyan   sleep      CD      1      1   0.162s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5D jovyan   sleep      CD      1      1   0.032s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YnijmLwy jovyan   compute.py  F      1      1   0.031s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YiqfxNdm jovyan   compute.py  F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YYgVHnyV jovyan   compute.py  F      1      1   0.062s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YYE7Ja9d jovyan   compute.py  F      1      1   0.048s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2Fr5PCm9h jovyan   ./sub_job+ CD      1      1   31.58s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆íS4xykqnw jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3wSjr2ik jovyan   echo       CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3wSjr2ij jovyan   echo       CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Rj jovyan   hostname   CD      1      1   0.030s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Ri jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Rh jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Rk jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsB jovyan   Hello I a+  F      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsA jovyan   Hello I a+  F      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgs9 jovyan   Hello I a+  F      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsC jovyan   Hello I a+  F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGjwQ2U jovyan   echo       CD      1      1   0.032s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGjwQ2T jovyan   echo       CD      1      1   0.027s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGjwQ2V jovyan   echo       CD      1      1   0.024s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQkA jovyan   echo       CD      1      1   0.024s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQkB jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQk9 jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQk8 jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQk7 jovyan   echo       CD      1      1   0.018s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGgyRTn jovyan   echo       CD      1      1   0.018s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGgyRTm jovyan   echo       CD      1      1   0.018s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiB jovyan   hostname   CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiC jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiD jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiE jovyan   hostname   CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhg jovyan   hostname   CD      1      1   0.016s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhf jovyan   hostname   CD      1      1   0.016s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhd jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhe jovyan   hostname   CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íp5VSGEC jovyan   echo       CD      1      1   0.051s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íp5TxGwq jovyan   echo       CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íp5VSGEB jovyan   echo       CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆ím4dLyPD jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íioKWajq jovyan   hostname   CD      4      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m    ∆íhFVr6U7 jovyan   false       F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆ígmdsbJF jovyan   hostname   CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "!flux jobs -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca4277",
   "metadata": {},
   "source": [
    "## flux cancel\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> Canceling running jobs\n",
    "</div>\n",
    "\n",
    "Since some of the jobs we see in the table above won't ever exit (and we didn't specify a timelimit), let's cancel them all now and free up the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46dd8ec8-6c64-4d8d-9a00-949f5f58c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flux-cancel: Canceled 4 jobs (0 errors)\n",
      "       JOBID USER     NAME       ST NTASKS NNODES     TIME INFO\n"
     ]
    }
   ],
   "source": [
    "# This was previously flux cancelall -f\n",
    "!flux cancel --all\n",
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e314e-98eb-487a-ad8e-1442840e37d8",
   "metadata": {},
   "source": [
    "## flux alloc\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> Allocation for an interactive instance\n",
    "</div>\n",
    "\n",
    "You might want to request an allocation for a set of resources (an allocation) and then attach to them interactively. This is the goal of flux alloc. Since we can't easily do that in a cell, try opening up the <button data-commandLinker-command=\"terminal:open\" data-name=\"flux\" href=\"#\">JupyterLab terminal</button> and doing: \n",
    "\n",
    "```bash\n",
    "# Look at the resources you have outside of the allocation\n",
    "flux resource list\n",
    "\n",
    "# Request an allocation with 2 \"nodes\" - a subset of what you have in total\n",
    "flux alloc -N 2\n",
    "\n",
    "# See the resources you are given\n",
    "flux resource list\n",
    "\n",
    "# You can exit from the allocation like this!\n",
    "exit\n",
    "```\n",
    "When you want to automate this, submitting work to an allocation, you would use `flux batch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544aa0a9",
   "metadata": {},
   "source": [
    "## flux batch\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:skyblue\">\n",
    "<span style=\"font-weight:600\">Description:</span> Submitting batch jobs\n",
    "</div>\n",
    "\n",
    "We can use the `flux batch` command to easily created nested flux instances.  When `flux batch` is invoked, Flux will automatically create a nested instance that spans the resources allocated to the job, and then Flux runs the batch script passed to `flux batch` on rank 0 of the nested instance. \"Rank\" refers to the rank of the Tree-Based Overlay Network (TBON) used by the [Flux brokers](https://flux-framework.readthedocs.io/projects/flux-core/en/latest/man1/flux-broker.html).\n",
    "\n",
    "While a batch script is expected to launch parallel jobs using `flux run` or `flux submit` at this level, nothing prevents the script from further batching other sub-batch-jobs using the `flux batch` interface, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "blank-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3Vw1mYfjD\n",
      "∆í3Vw6xW9wD\n"
     ]
    }
   ],
   "source": [
    "!flux batch --nslots=2 --cores-per-slot=1 --nodes=2 ./sleep_batch.sh\n",
    "!flux batch --nslots=2 --cores-per-slot=1 --nodes=2 ./sleep_batch.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98bfa1",
   "metadata": {},
   "source": [
    "Take a quick look at [sleep_batch.sh](sleep_batch.sh) to see what we are about to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edff8993-3c39-4f46-939d-4c8be5739fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3VwC9Te9D\n",
      "       JOBID USER     NAME       ST NTASKS NNODES     TIME INFO\n",
      "\u001b[01;34m  ∆í3Vw6xW9wD jovyan   ./sleep_b+  R      2      2   0.368s 8660c254a8e[5,5]\n",
      "\u001b[0;0m\u001b[01;34m  ∆í3Vw1mYfjD jovyan   ./sleep_b+  R      2      2   0.572s 8660c254a8e[5,5]\n",
      "\u001b[0;0m       JOBID USER     NAME       ST NTASKS NNODES     TIME INFO\n",
      "\u001b[01;34m  ∆í3Vw6xW9wD jovyan   ./sleep_b+  R      2      2   0.536s 8660c254a8e[5,5]\n",
      "\u001b[0;0m\u001b[01;34m  ∆í3Vw1mYfjD jovyan   ./sleep_b+  R      2      2   0.741s 8660c254a8e[5,5]\n",
      "\u001b[0;0m\n",
      "∆í3Vw6xW9wD:\n",
      "\n",
      "∆í3Vw1mYfjD:\n"
     ]
    }
   ],
   "source": [
    "# Here we are submitting a job that generates output, and asking to write it to /tmp/cheese.txt\n",
    "!flux submit --out /tmp/cheese.txt echo \"Sweet dreams üåöÔ∏è are made of cheese, who am I to diss a brie? üßÄÔ∏è\"\n",
    "\n",
    "# This will show us JOBIDs\n",
    "!flux jobs\n",
    "\n",
    "# We can even see jobs in sub-instances with \"-R\" (for recursive)\n",
    "!flux jobs -R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b135c-ece7-45f7-b25d-dc90ba5f44f7",
   "metadata": {},
   "source": [
    "### `flux job`\n",
    "\n",
    "Let's next inspect the last job we ran with `flux job info` and target the last job identifier with `flux job last`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "429eb39d-d19c-4170-9707-ca8c3b2bfe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"version\": 1, \"execution\": {\"R_lite\": [{\"rank\": \"2\", \"children\": {\"core\": \"7\"}}], \"nodelist\": [\"8660c254a8e5\"], \"starttime\": 1721520196, \"expiration\": 4875116178}}\n",
      "0: stdout redirected to /tmp/cheese.txt\n",
      "0: stderr redirected to /tmp/cheese.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span>Sweet dreams üåöÔ∏è are made of cheese, who am I to diss a brie? üßÄÔ∏è\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "Sweet dreams üåöÔ∏è are made of cheese, who am I to diss a brie? üßÄÔ∏è\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "Sweet dreams üåöÔ∏è are made of cheese, who am I to diss a brie? üßÄÔ∏è"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note here we are using flux job last to see the last job id\n",
    "# The \"R\" here asks for the resource spec\n",
    "!flux job info $(flux job last) R\n",
    "\n",
    "# When we attach it will direct us to our output file\n",
    "!flux job attach $(flux job last)\n",
    "\n",
    "# And we can look at the output file to see our expected output!\n",
    "from IPython.display import Code\n",
    "Code(filename='/tmp/cheese.txt', language='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e525e2-6c89-4c14-9fae-d87a0d4fc574",
   "metadata": {},
   "source": [
    "We can again see a list all completed jobs with `flux jobs -a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df8a8b7c-f475-4a51-8bc6-9983dc9d78ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       JOBID USER     NAME       ST NTASKS NNODES     TIME INFO\n",
      "\u001b[01;34m  ∆í3Vw6xW9wD jovyan   ./sleep_b+  R      2      2   0.998s 8660c254a8e[5,5]\n",
      "\u001b[0;0m\u001b[01;34m  ∆í3Vw1mYfjD jovyan   ./sleep_b+  R      2      2   1.202s 8660c254a8e[5,5]\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VwC9Te9D jovyan   echo       CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[37m    ∆ínyvM4Nb jovyan   sleep      CA      2      1   5.269h 8660c254a8e5\n",
      "\u001b[0;0m\u001b[37m  ∆í3VqVSHr7q jovyan   sleep      CA      2      1   12.04s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[37m  ∆í3VqzNXq8B jovyan   analysis   CA      1      1   10.91s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[37m  ∆í3VqtrJWFh jovyan   simulation CA      2      2   11.12s 8660c254a8e[5,5]\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3Vr6FWywV jovyan   job-watch+ CD      1      1   10.03s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3Vqogq1L3 jovyan   echo       CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3Vqogq1L4 jovyan   echo       CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAUA jovyan   hostname   CD      1      1   0.060s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAU9 jovyan   hostname   CD      1      1   0.050s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAU8 jovyan   hostname   CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqhAnAU7 jovyan   hostname   CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqadFLKq jovyan   echo       CD      1      1   0.025s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqabmM3W jovyan   echo       CD      1      1   0.025s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqabmM3V jovyan   echo       CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqNqo3Qs jovyan   hostname   CD      1      1   0.016s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VqBbUVR9 jovyan   hostname   CD      4      1   0.017s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í3Vq5LFXNf jovyan   false       F      1      1   0.037s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VpyWEM83 jovyan   hostname   CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3VPB8ZEqV jovyan   echo       CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3V7Tprhqh jovyan   echo       CD      1      1   0.060s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í3V35oKmEo jovyan   echo       CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2mzETcgvB jovyan   echo       CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2mnMLCXPd jovyan   echo       CD      1      1   0.036s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2mfhe5NCX jovyan   echo       CD      1      1   0.036s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FE jovyan   sleep      CD      1      1   0.077s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y2 jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y8 jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xx jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y5 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y7 jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y1 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xs jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xt jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y3 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gd jovyan   sleep      CD      1      1   0.118s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y4 jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FF jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FG jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xv jovyan   sleep      CD      1      1   0.117s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FH jovyan   sleep      CD      1      1   0.073s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xu jovyan   sleep      CD      1      1   0.117s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF545FD jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xw jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5y6 jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xz jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gc jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gb jovyan   sleep      CD      1      1   0.087s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF3a5xy jovyan   sleep      CD      1      1   0.086s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gX jovyan   sleep      CD      1      1   0.101s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QK jovyan   sleep      CD      1      1   0.109s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QJ jovyan   sleep      CD      1      1   0.107s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QD jovyan   sleep      CD      1      1   0.111s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QG jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gY jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266ga jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEF266gZ jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QL jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QH jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QF jovyan   sleep      CD      1      1   0.077s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QE jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QC jovyan   sleep      CD      1      1   0.062s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887z jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887y jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEzc7QB jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887w jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887x jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887v jovyan   sleep      CD      1      1   0.088s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZN jovyan   sleep      CD      1      1   0.091s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887s jovyan   sleep      CD      1      1   0.088s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887u jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEwe8qV jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZL jovyan   sleep      CD      1      1   0.077s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887r jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887t jovyan   sleep      CD      1      1   0.073s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZM jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEy887q jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEwe8qW jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZG jovyan   sleep      CD      1      1   0.082s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZF jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9Z9 jovyan   sleep      CD      1      1   0.094s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZE jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZB jovyan   sleep      CD      1      1   0.094s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZA jovyan   sleep      CD      1      1   0.094s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZH jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZK jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZJ jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH6 jovyan   sleep      CD      1      1   0.081s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZD jovyan   sleep      CD      1      1   0.069s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEvA9ZC jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH3 jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH5 jovyan   sleep      CD      1      1   0.072s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH2 jovyan   sleep      CD      1      1   0.064s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH1 jovyan   sleep      CD      1      1   0.067s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGw jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGx jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAH4 jovyan   sleep      CD      1      1   0.063s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGz jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGv jovyan   sleep      CD      1      1   0.083s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzd jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGy jovyan   sleep      CD      1      1   0.058s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGt jovyan   sleep      CD      1      1   0.059s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGu jovyan   sleep      CD      1      1   0.058s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzb jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzc jovyan   sleep      CD      1      1   0.108s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAza jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAze jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGq jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGr jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGp jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGs jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzY jovyan   sleep      CD      1      1   0.088s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzZ jovyan   sleep      CD      1      1   0.085s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzf jovyan   sleep      CD      1      1   0.084s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzi jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEtgAGo jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzg jovyan   sleep      CD      1      1   0.080s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzj jovyan   sleep      CD      1      1   0.071s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzW jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzX jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiM jovyan   sleep      CD      1      1   0.112s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiJ jovyan   sleep      CD      1      1   0.111s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzh jovyan   sleep      CD      1      1   0.062s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiK jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiL jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiH jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzT jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzV jovyan   sleep      CD      1      1   0.092s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEsCAzU jovyan   sleep      CD      1      1   0.092s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiG jovyan   sleep      CD      1      1   0.087s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiA jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiF jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiD jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiE jovyan   sleep      CD      1      1   0.070s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRy jovyan   sleep      CD      1      1   0.069s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBi9 jovyan   sleep      CD      1      1   0.068s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBi8 jovyan   sleep      CD      1      1   0.066s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiB jovyan   sleep      CD      1      1   0.065s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBiC jovyan   sleep      CD      1      1   0.064s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEqiBi7 jovyan   sleep      CD      1      1   0.064s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRu jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRw jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRt jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRx jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRr jovyan   sleep      CD      1      1   0.053s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRv jovyan   sleep      CD      1      1   0.048s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRs jovyan   sleep      CD      1      1   0.048s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRq jovyan   sleep      CD      1      1   0.059s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRp jovyan   sleep      CD      1      1   0.114s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9d jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9Y jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9e jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9b jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9W jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRm jovyan   sleep      CD      1      1   0.122s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9f jovyan   sleep      CD      1      1   0.122s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9a jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9Z jovyan   sleep      CD      1      1   0.123s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9X jovyan   sleep      CD      1      1   0.122s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDsC jovyan   sleep      CD      1      1   0.100s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9c jovyan   sleep      CD      1      1   0.099s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9U jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9T jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9R jovyan   sleep      CD      1      1   0.095s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRn jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9S jovyan   sleep      CD      1      1   0.093s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEnkD9V jovyan   sleep      CD      1      1   0.091s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEpECRo jovyan   sleep      CD      1      1   0.090s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvN jovyan   sleep      CD      1      1   0.105s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs5 jovyan   sleep      CD      1      1   0.105s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs8 jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvQ jovyan   sleep      CD      1      1   0.105s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs9 jovyan   sleep      CD      1      1   0.103s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs7 jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDs6 jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvP jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvR jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvS jovyan   sleep      CD      1      1   0.104s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDsB jovyan   sleep      CD      1      1   0.078s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvK jovyan   sleep      CD      1      1   0.079s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvJ jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvT jovyan   sleep      CD      1      1   0.075s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvM jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvL jovyan   sleep      CD      1      1   0.076s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvU jovyan   sleep      CD      1      1   0.071s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEmGDsA jovyan   sleep      CD      1      1   0.069s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvH jovyan   sleep      CD      1      1   0.074s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe7 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvG jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe4 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe6 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEQWPvF jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe5 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe8 jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMm jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMg jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMf jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMi jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdy jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdv jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMh jovyan   sleep      CD      1      1   0.193s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe2 jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe3 jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdw jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdz jovyan   sleep      CD      1      1   0.192s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe9 jovyan   sleep      CD      1      1   0.191s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMp jovyan   sleep      CD      1      1   0.175s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMj jovyan   sleep      CD      1      1   0.173s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdx jovyan   sleep      CD      1      1   0.174s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMq jovyan   sleep      CD      1      1   0.173s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qe1 jovyan   sleep      CD      1      1   0.174s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMn jovyan   sleep      CD      1      1   0.171s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMZ jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5G jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5F jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5E jovyan   sleep      CD      1      1   0.168s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEP2Qdu jovyan   sleep      CD      1      1   0.166s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMo jovyan   sleep      CD      1      1   0.167s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMk jovyan   sleep      CD      1      1   0.166s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMd jovyan   sleep      CD      1      1   0.165s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMb jovyan   sleep      CD      1      1   0.163s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMe jovyan   sleep      CD      1      1   0.162s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMa jovyan   sleep      CD      1      1   0.162s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEMYRMc jovyan   sleep      CD      1      1   0.162s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2eEEL4S5D jovyan   sleep      CD      1      1   0.032s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YnijmLwy jovyan   compute.py  F      1      1   0.031s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YiqfxNdm jovyan   compute.py  F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YYgVHnyV jovyan   compute.py  F      1      1   0.062s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YYE7Ja9d jovyan   compute.py  F      1      1   0.048s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m  ∆í2Fr5PCm9h jovyan   ./sub_job+ CD      1      1   31.58s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆íS4xykqnw jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3wSjr2ik jovyan   echo       CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3wSjr2ij jovyan   echo       CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Rj jovyan   hostname   CD      1      1   0.030s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Ri jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Rh jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3mYvC1Rk jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsB jovyan   Hello I a+  F      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsA jovyan   Hello I a+  F      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgs9 jovyan   Hello I a+  F      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsC jovyan   Hello I a+  F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGjwQ2U jovyan   echo       CD      1      1   0.032s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGjwQ2T jovyan   echo       CD      1      1   0.027s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGjwQ2V jovyan   echo       CD      1      1   0.024s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQkA jovyan   echo       CD      1      1   0.024s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQkB jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQk9 jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQk8 jovyan   echo       CD      1      1   0.023s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGiTQk7 jovyan   echo       CD      1      1   0.018s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGgyRTn jovyan   echo       CD      1      1   0.018s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í3VGgyRTm jovyan   echo       CD      1      1   0.018s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiB jovyan   hostname   CD      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiC jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiD jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m   ∆í2rpm1UiE jovyan   hostname   CD      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhg jovyan   hostname   CD      1      1   0.016s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhf jovyan   hostname   CD      1      1   0.016s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhd jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íxah9Lhe jovyan   hostname   CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íp5VSGEC jovyan   echo       CD      1      1   0.051s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íp5TxGwq jovyan   echo       CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íp5VSGEB jovyan   echo       CD      1      1   0.047s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆ím4dLyPD jovyan   hostname   CD      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆íioKWajq jovyan   hostname   CD      4      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m    ∆íhFVr6U7 jovyan   false       F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;32m    ∆ígmdsbJF jovyan   hostname   CD      1      1   0.013s 8660c254a8e5\n",
      "\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "!flux jobs -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e415ecc-f451-4909-a2bf-351a639cd7fa",
   "metadata": {},
   "source": [
    "To restrict the output to failed (i.e., jobs that exit with nonzero exit code, time out, or are canceled or killed) jobs, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "032597d2-4b02-47ea-a5e5-915313cdd7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       JOBID USER     NAME       ST NTASKS NNODES     TIME INFO\n",
      "\u001b[01;31m  ∆í3Vq5LFXNf jovyan   false       F      1      1   0.037s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YnijmLwy jovyan   compute.py  F      1      1   0.031s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YiqfxNdm jovyan   compute.py  F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YYgVHnyV jovyan   compute.py  F      1      1   0.062s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m  ∆í2YYE7Ja9d jovyan   compute.py  F      1      1   0.048s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsB jovyan   Hello I a+  F      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsA jovyan   Hello I a+  F      1      1   0.014s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgs9 jovyan   Hello I a+  F      1      1   0.015s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m   ∆í3cZKNgsC jovyan   Hello I a+  F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m\u001b[01;31m    ∆íhFVr6U7 jovyan   false       F      1      1   0.012s 8660c254a8e5\n",
      "\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "!flux jobs -f failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc17bac-2fc4-4418-8939-e930f9929976",
   "metadata": {},
   "source": [
    "### flux submit from within a batch\n",
    "\n",
    "Next open up [hello-batch.sh](hello-batch.sh) to see an example of using `flux batch` to submit jobs within the instance, and then wait for them to finish. This script is going to:\n",
    "\n",
    "1. Create a flux instance with the top level resources you specify\n",
    "2. Submit jobs to the scheduler controlled by the broker of that sub-instance\n",
    "3. Run the four jobs, with `--flags=waitable` and `flux job wait --all` to wait for the output file\n",
    "4. Within the batch script, you can add `--wait` or `--flags=waitable` to individual jobs, and use `flux queue drain` to wait for the queue to drain, _or_ `flux job wait --all` to wait for the jobs you flagged to finish. \n",
    "\n",
    "Note that when you submit a batch job, you'll get a job id back for the _batch job_, and usually when you look at the output of that with `flux job attach $jobid` you will see the output file(s) where the internal contents are written. Since we want to print the output file easily to the terminal, we are waiting for the batch job by adding the `--flags=waitable` and then waiting for it. Let's try to run our batch job now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72358a03-6f1f-4c5e-91eb-cab71883a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3VwkUsydR\n",
      "∆í3VwkUsydR\n",
      "Hello job 1 from 8660c254a8e5 üíõÔ∏è\n",
      "Hello job 2 from 8660c254a8e5 üíöÔ∏è\n",
      "Hello job 3 from 8660c254a8e5 üíôÔ∏è\n",
      "Hello job 4 from 8660c254a8e5 üíúÔ∏è\n"
     ]
    }
   ],
   "source": [
    "! flux batch --flags=waitable --out /tmp/flux-batch.out -N2 ./hello-batch.sh\n",
    "! flux job wait\n",
    "! cat /tmp/hello-batch-1.out\n",
    "! cat /tmp/hello-batch-2.out\n",
    "! cat /tmp/hello-batch-3.out\n",
    "! cat /tmp/hello-batch-4.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0ae3f-2813-4ae8-83be-00be3df92a4b",
   "metadata": {},
   "source": [
    "Each of `flux batch` and `flux alloc` hints at creating a Flux instance. How deep can we go into that rabbit hole, perhaps for jobs and workflows with nested logic or more orchestration complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b405b1-219f-489c-abfc-e2983e82124a",
   "metadata": {},
   "source": [
    "### The Flux Hierarchy üçáÔ∏è\n",
    "\n",
    "One feature of the Flux Framework scheduler that is unique is its ability to submit jobs within instances, where an instance can be thought of as a level in a graph. Let's start with a basic image - this is what it might look like to submit to a scheduler that is not graph-based (left), where all jobs go to a central job queue or database. Note that our maximum job throughput is one job per second. The throughput is limited by the workload manager's ability to process a single job. We can improve upon this by simply adding another level, perhaps with three instances. For example, let's say we create a flux allocation or batch that has control of some number of child nodes. We might launch three new instances (each with its own scheduler and queue, right image) at that level two, and all of a sudden, we get a throughput of 1x3, or three jobs per second.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td>\n",
    "<img src=\"img/single-submit.png\" style=\"float:left; margin-top:30px\" width=\"350px\">        \n",
    "    </td>\n",
    "    <td>\n",
    "<img src=\"img/instance-submit.png\" style=\"float:right; margin-top:-20px\" width=\"550px\">        \n",
    "    </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "All of a sudden, the throughout can increase exponentially because we are essentially submitting to different schedulers. The example above is not impressive, but our [learning guide](https://flux-framework.readthedocs.io/en/latest/guides/learning_guide.html#fully-hierarchical-resource-management-techniques) (Figure 10) has a beautiful example of how it can scale, done via an actual experiment. We were able to submit 500 jobs/second using only three levels, vs. close to 1 job/second with one level. For an interesting detail, you can vary the scheduler algorithm or topology within each sub-instance, meaning that you can do some fairly interesting things with scheduling work, and all without stressing the top level system instance. \n",
    "\n",
    "Now that we understand nested instances, let's look at another batch example that better uses them. Here we have two job scripts:\n",
    "\n",
    "- [sub_job1.sh](sub_job1.sh): Is going to be run with `flux batch` and submit sub_job2.sh\n",
    "- [sub_job2.sh](sub_job2.sh): Is going to be submitted by sub_job1.sh.\n",
    "\n",
    "Take a look at each script to see how they work, and then submit it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8640a611-38e4-42b1-a913-89e0c76c8014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3Vxb9eQBy\n"
     ]
    }
   ],
   "source": [
    "!flux batch -N1 ./sub_job1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c3a4a-2b77-4ab9-8e0c-9f5228e61016",
   "metadata": {},
   "source": [
    "And now that we've submitted, let's look at the hierarchy for all the jobs we just ran. Here is how to try flux pstree, which normally can show jobs in an instance, but it has limited functionality given we are in a notebook! So instead of just running the single command, let's add \"-a\" to indicate \"show me ALL jobs.\"\n",
    "More complex jobs and in a different environment would have deeper nesting. You can [see examples here](https://flux-framework.readthedocs.io/en/latest/jobs/hierarchies.html?h=pstree#flux-pstree-command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d2b1f0b-e6c2-4583-8068-7c76fa341884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "‚îú‚îÄ‚îÄ ./sub_job1.sh\n",
      "‚îú‚îÄ‚îÄ ./sleep_batch.sh\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ sleep:R\n",
      "‚îú‚îÄ‚îÄ ./sleep_batch.sh\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ sleep:R\n",
      "‚îú‚îÄ‚îÄ ./hello-batch.sh:CD\n",
      "‚îú‚îÄ‚îÄ 28*[echo:CD]\n",
      "‚îú‚îÄ‚îÄ 2*[sleep:CA]\n",
      "‚îú‚îÄ‚îÄ analysis:CA\n",
      "‚îú‚îÄ‚îÄ simulation:CA\n",
      "‚îú‚îÄ‚îÄ job-watch.sh:CD\n",
      "‚îú‚îÄ‚îÄ 22*[hostname:CD]\n",
      "‚îú‚îÄ‚îÄ 2*[false:F]\n",
      "‚îú‚îÄ‚îÄ 200*[sleep:CD]\n",
      "‚îú‚îÄ‚îÄ 4*[compute.py:F]\n",
      "‚îú‚îÄ‚îÄ ./sub_job1.sh:CD\n",
      "‚îú‚îÄ‚îÄ Hello I am job 3:F\n",
      "‚îú‚îÄ‚îÄ Hello I am job 2:F\n",
      "‚îú‚îÄ‚îÄ Hello I am job 1:F\n",
      "‚îî‚îÄ‚îÄ Hello I am job 4:F\n"
     ]
    }
   ],
   "source": [
    "!flux pstree -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724130f-b0db-4ccf-a01e-98907b9a27ca",
   "metadata": {},
   "source": [
    "You can also try a more detailed view with `flux pstree -a -X`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72567af7-aa40-46b7-be43-c9e8124c1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flux-archive: shared-file.txt: write: Attempt to overwrite existing file\n",
      "flux-archive: shared-file.txt: write: Attempt to overwrite existing file\n",
      "flux-archive: shared-file.txt: write: Attempt to overwrite existing file\n",
      "[1-3]: Exit 1\n"
     ]
    }
   ],
   "source": [
    "!flux exec -r all -x 0 flux archive extract --name myarchive --directory $(pwd) shared-file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1a33c-9f9e-4ba0-a013-e97601f79e41",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Process, Monitoring, and Job Utilities ‚öôÔ∏è\n",
    "\n",
    "## flux exec üëäÔ∏è\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Executing commands across ranks\n",
    "</div>\n",
    "\n",
    "Have you ever wanted a quick way to execute a command to all of your nodes in a flux instance? It might be to create a directory, or otherwise interact with a file. This can be hugely useful in environments where you don't have a shared filesystem, for example. This is a job for flux exec! Here is a toy example to execute the command to every rank (`-r all`) to print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df8e5a5d-76aa-4151-a25f-4d8f3aa4a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from a flux rank!\n",
      "Hello from a flux rank!\n",
      "Hello from a flux rank!\n",
      "Hello from a flux rank!\n"
     ]
    }
   ],
   "source": [
    "!flux exec -r all echo \"Hello from a flux rank!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c05fe-461e-4f88-bb3d-c74f9d8bc217",
   "metadata": {},
   "source": [
    "You can also use `-x` to exclude ranks. For example, we often do custom actions on the main or \"leader\" rank, and just want to issue commands to the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a9f7e0d-edf4-459e-93ac-463ce0635e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from everyone except the lead (0) rank!\n",
      "Hello from everyone except the lead (0) rank!\n",
      "Hello from everyone except the lead (0) rank!\n"
     ]
    }
   ],
   "source": [
    "! flux exec -r all -x 0 echo \"Hello from everyone except the lead (0) rank!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05404084-55df-4067-9512-e4ef16ca272e",
   "metadata": {},
   "source": [
    "Here is a similar example, but asking to execute only on rank 2, and to have it print the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9507c7b-de5c-4129-9a99-c943614a9ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "!flux exec -r 2 flux getattr rank "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb6f4d-cbff-4f0a-98b1-59d5a99ee58f",
   "metadata": {},
   "source": [
    "And of course, we could do the same to print for all ranks! This is a derivative of the first example we showed you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a9de119-abc4-4917-a339-2010ccc7b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "!flux exec flux getattr rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2676cbc-e883-4d72-a719-67bc46182270",
   "metadata": {},
   "source": [
    "You can imagine that `flux exec` is hugely useful in the context of batch jobs, and specific use cases with files, such as using `flux archive`, discussed next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be923293-6fa1-4a4e-a3b4-8d462d021919",
   "metadata": {},
   "source": [
    "## flux archive üìöÔ∏è\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Creating file and content archives to access later and between ranks\n",
    "</div>\n",
    "\n",
    "As Flux is used more in cloud environments, we might find ourselves in a situation where we have a cluster without a shared filesystem. The `flux archive` command helps with this situation. At a high level, `flux archive` allows us to save named pieces of data (e.g., files) to the Flux KVS for later retrieval.\n",
    "\n",
    "When using `flux archive`, we first have to create an named archive. In the code below, we will create a text file and then save it into an archive using `flux archive`. Note that, for larger files, you can speed up the creation and extraction of archives by using the `--mmap` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3928d581-9815-4f7b-98cb-72d6a804813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Sweet dreams üåöÔ∏è are made of cheese, who am I to diss a brie? üßÄÔ∏è\" > shared-file.txt\n",
    "!flux archive create --name myarchive --directory $(pwd) shared-file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341da82-b8f0-445c-b335-6a10271994d9",
   "metadata": {},
   "source": [
    "When we run this code, we are creating an archive in the leader broker. Now that the archive is created, we will want to extract its contents onto the other nodes of our cluster. To do this, we first need to ensure that the directory that we will extract into exists on those nodes. This can be done using `flux exec`. The `flux exec` command will execute a command on the nodes associated with specified brokers. Let's use `flux exec` to run `mkdir` on all the nodes of our cluster except the leader broker's node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bf40c7b-3ca3-4e4f-b21c-4e843c7562a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux exec -r all -x 0 mkdir -p $(pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913e925-aefc-400e-9ff3-0f541f9c3ed2",
   "metadata": {},
   "source": [
    "The flags provided to `flux exec` do the following:\n",
    "* `-r all`: run across all brokers in the Flux instance\n",
    "* `-x 0`: don't runn on broker 0 (i.e., the leader broker)\n",
    "\n",
    "Now that the directory has been created on all our nodes, we can extract the archive onto those nodes by combining `flux exec` and `flux archive extract`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35f8a6-869b-4f4f-874a-074919dfcc51",
   "metadata": {},
   "source": [
    "Finally, when we're done with the archive, we can remove it with `flux archive remove`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38472bab-c7b9-409b-9058-734527898eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux archive remove --name myarchive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa64ca-ebde-4c5f-a505-7ca2b0173f98",
   "metadata": {},
   "source": [
    "Finally, note that `flux archive` was named `flux filemap` in earlier versions of Flux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e110ce-db7a-4066-81f7-7191c1968496",
   "metadata": {},
   "source": [
    "## flux uptime\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Showing how long a flux instance has been running\n",
    "</div>\n",
    "\n",
    "Did someone say... [uptime](https://youtu.be/SYRlTISvjww?si=zDlvpWbBljUmZw_Q)? ‚òùÔ∏èüïëÔ∏èüï∫Ô∏è\n",
    "\n",
    "Flux provides an `uptime` utility to display properties of the Flux instance such as state of the current instance, how long it has been running, its size and if scheduling is disabled or stopped. The output shows how long the instance has been up, the instance owner, the instance depth (depth in the Flux hierarchy), and the size of the instance (number of brokers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "095f2ac3-145b-4cda-8350-7c281f2b2b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 00:03:20 run 5.3h,  owner jovyan,  depth 0,  size 4\n"
     ]
    }
   ],
   "source": [
    "!flux uptime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2ae62-3e3b-4c82-a0c7-4c97ff1376d2",
   "metadata": {},
   "source": [
    "## flux top \n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Showing a table of real-time Flux processes\n",
    "</div>\n",
    "\n",
    "Flux provides a feature-full version of `top` for nested Flux instances and jobs. In the <button data-commandLinker-command=\"terminal:open\" data-name=\"flux\" href=\"#\">JupyterLab terminal</button> invoke `flux top` to see the \"sleep\" jobs. If they have already completed you can resubmit them. \n",
    "\n",
    "We recommend not running `flux top` in the notebook as it is not designed to display output from a command that runs continuously.\n",
    "\n",
    "## flux pstree \n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Showing a flux process tree (and seeing nesting in instances)\n",
    "</div>\n",
    "\n",
    "In analogy to `top`, Flux provides `flux pstree`. Try it out in the <button data-commandLinker-command=\"terminal:open\" data-name=\"flux\" href=\"#\">JupyterLab terminal</button> or here in the notebook.\n",
    "\n",
    "## flux proxy\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Interacting with a job hierarchy\n",
    "</div>\n",
    "\n",
    "Flux proxy is used to route messages to and from a Flux instance. We can use `flux proxy` to connect to a running Flux instance and then submit more nested jobs inside it. From the <button data-commandLinker-command=\"terminal:open\" data-name=\"flux\" href=\"#\">JupyterLab terminal</button> run the commands below!\n",
    "\n",
    "```bash\n",
    "# Outputs the JOBID\n",
    "flux batch --nslots=2 --cores-per-slot=1 --nodes=2 ./sleep_batch.sh\n",
    "\n",
    "# Put the JOBID into an environment variable\n",
    "JOBID=$(flux job last)\n",
    "\n",
    "# See the flux process tree\n",
    "flux pstree -a\n",
    "\n",
    "# Connect to the Flux instance corresponding to JOBID above\n",
    "flux proxy ${JOBID}\n",
    "\n",
    "# Note the depth is now 1 and the size is 2: we're one level deeper in a Flux hierarchy and we have only 2 brokers now.\n",
    "flux uptime\n",
    "\n",
    "# This instance has 2 \"nodes\" and 2 cores allocated to it\n",
    "flux resource list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e04b6-7427-4c77-8eb0-b5b8998c6224",
   "metadata": {},
   "source": [
    "## flux queue\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Interacting with and inspecting Flux queues\n",
    "</div>\n",
    "\n",
    "Flux has a command for controlling the queue within the `job-manager`: `flux queue`.  This includes disabling job submission, re-enabling it, waiting for the queue to become idle or empty, and checking the queue status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "800de4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job submission is disabled: maintenance outage\n",
      "Job submission is enabled\n",
      "usage: flux-queue [-h] {status,list,enable,disable,start,stop,drain,idle} ...\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "subcommands:\n",
      "\n",
      "  {status,list,enable,disable,start,stop,drain,idle}\n"
     ]
    }
   ],
   "source": [
    "!flux queue disable \"maintenance outage\"\n",
    "!flux queue enable\n",
    "!flux queue -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958b3ce-9220-48ad-8f3e-f76c8d6a800c",
   "metadata": {},
   "source": [
    "## flux getattr\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Getting attributes about your system and environment\n",
    "</div>\n",
    "\n",
    "Each Flux instance has a set of attributes that are set at startup that affect the operation of Flux, such as `rank`, `size`, and `local-uri` (the Unix socket usable for communicating with Flux).  Many of these attributes can be modified at runtime, such as `log-stderr-level` (1 logs only critical messages to stderr while 7 logs everything, including debug messages). Here is an example set that you might be interested in looking at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "biblical-generic",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "local:///tmp/flux-iwjuLe/local-0\n",
      "broker.boot-method                      simple\n",
      "broker.critical-ranks                   0\n",
      "broker.mapping                          [[0,1,4,1]]\n",
      "broker.pid                              8\n",
      "broker.quorum                           4\n",
      "broker.quorum-timeout                   1m\n",
      "broker.rc1_path                         /etc/flux/rc1\n",
      "broker.rc3_path                         /etc/flux/rc3\n",
      "broker.starttime                        1721501121.61\n",
      "conf.shell_initrc                       /etc/flux/shell/initrc.lua\n",
      "conf.shell_pluginpath                   /usr/lib/flux/shell/plugins\n",
      "config.path                             -\n",
      "content.backing-module                  content-sqlite\n",
      "content.hash                            sha1\n",
      "hostlist                                8660c254a8e[5,5,5,5]\n",
      "instance-level                          0\n",
      "jobid                                   -\n",
      "local-uri                               local:///tmp/flux-iwjuLe/local-0\n",
      "log-critical-level                      2\n",
      "log-filename                            -\n",
      "log-forward-level                       7\n",
      "log-level                               7\n",
      "log-ring-size                           1024\n",
      "log-stderr-level                        3\n",
      "log-stderr-mode                         leader\n",
      "parent-kvs-namespace                    -\n",
      "parent-uri                              -\n",
      "rank                                    0\n",
      "rundir                                  /tmp/flux-iwjuLe\n",
      "security.owner                          1000\n",
      "size                                    4\n",
      "statedir                                -\n",
      "tbon.child_rcvhwm                       0\n",
      "tbon.connect_timeout                    30s\n",
      "tbon.descendants                        3\n",
      "tbon.endpoint                           ipc:///tmp/flux-iwjuLe/tbon-0\n",
      "tbon.level                              0\n",
      "tbon.maxlevel                           1\n",
      "tbon.parent-endpoint                    -\n",
      "tbon.prefertcp                          0\n",
      "tbon.tcp_user_timeout                   20s\n",
      "tbon.topo                               kary:32\n",
      "tbon.torpid_max                         30s\n",
      "tbon.torpid_min                         5s\n",
      "tbon.zmq_io_threads                     1\n",
      "tbon.zmqdebug                           0\n",
      "version                                 0.63.0-5-g0ddc3d9e8\n"
     ]
    }
   ],
   "source": [
    "!flux getattr rank\n",
    "!flux getattr size\n",
    "!flux getattr local-uri\n",
    "!flux setattr log-stderr-level 3\n",
    "!flux lsattr -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78568c0-7b78-4a1c-aa7f-40d7ea43620f",
   "metadata": {},
   "source": [
    "## flux module\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Managing Flux extension modules\n",
    "</div>\n",
    "\n",
    "Services within a Flux instance are implemented by modules. To query and manage broker modules, use `flux module`.  Modules that we have already directly interacted with in this tutorial include `resource` (via `flux resource`), `job-ingest` (via `flux` and the Python API) `job-list` (via `flux jobs`) and `job-manager` (via `flux queue`). For the most part, services are implemented by modules of the same name.  In some circumstances, where multiple implementations for a service exist, a module of a different name implements a given service (e.g., in this instance, `sched-fluxion-qmanager` provides the `sched` service and thus `sched.alloc`, but in another instance `sched-simple` might provide the `sched` service)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "spatial-maintenance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                   Idle  S Service\n",
      "job-exec                    2  R \n",
      "heartbeat                   0  R \n",
      "job-list                    2  R \n",
      "sched-fluxion-qmanager      2  R sched\n",
      "content-sqlite              1  R content-backing\n",
      "resource                    1  R \n",
      "job-ingest                  2  R \n",
      "content                     1  R \n",
      "job-info                    5  R \n",
      "kvs-watch                   5  R \n",
      "sched-fluxion-resource      2  R \n",
      "kvs                         1  R \n",
      "cron                     idle  R \n",
      "job-manager                 0  R \n",
      "barrier                  idle  R \n",
      "connector-local             0  R 1000-shell-f3Vw1mYfjD,1000-shell-f3Vw6xW9wD\n"
     ]
    }
   ],
   "source": [
    "!flux module list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c7d50b-50d2-4190-a42e-9b13f1f30380",
   "metadata": {},
   "source": [
    "See the [Flux Management Notebook](02_flux_framework.ipynb) for a small tutorial of unloading and reloading the Fluxion (flux scheduler) modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea958f-e12c-4229-b8a6-e40dcfbd0692",
   "metadata": {},
   "source": [
    "## flux dmesg\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Viewing Flux system messages\n",
    "</div>\n",
    "\n",
    "\n",
    "If you need some additional help debugging your Flux setup, you might be interested in `flux dmesg`, which is akin to the [Linux dmesg](https://man7.org/linux/man-pages/man1/dmesg.1.html) but delivers messages for Flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c34899ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-20T22:56:18.760174Z\u001b[0m \u001b[33mbroker.debug[0]\u001b[0m: \u001b[34mrmmod sched-simple\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.760532Z\u001b[0m \u001b[33mbroker.debug[0]\u001b[0m: \u001b[34mmodule sched-simple exited\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.760597Z\u001b[0m \u001b[33mresource.debug[0]\u001b[0m: \u001b[34maborted 1 resource.acquire(s)\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.760615Z\u001b[0m \u001b[33mjob-manager.debug[0]\u001b[0m: \u001b[34malloc: stop due to disconnect: Success\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.879655Z\u001b[0m \u001b[33mbroker.debug[0]\u001b[0m: \u001b[34minsmod sched-fluxion-resource\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.879925Z\u001b[0m \u001b[33msched-fluxion-resource.info[0]\u001b[0m: version 0.34.0-38-g0fad5268\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.879954Z\u001b[0m \u001b[33msched-fluxion-resource.debug[0]\u001b[0m: \u001b[34mmod_main: resource module starting\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.880319Z\u001b[0m \u001b[33msched-fluxion-resource.warning[0]\u001b[0m: \u001b[1mcreate_reader: allowlist unsupported\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.880472Z\u001b[0m \u001b[33msched-fluxion-resource.debug[0]\u001b[0m: \u001b[34mresource graph datastore loaded with rv1exec reader\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.880477Z\u001b[0m \u001b[33msched-fluxion-resource.info[0]\u001b[0m: populate_resource_db: loaded resources from core's resource.acquire\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.880519Z\u001b[0m \u001b[33msched-fluxion-resource.debug[0]\u001b[0m: \u001b[34mresource status changed (rankset=[all] status=DOWN)\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.880522Z\u001b[0m \u001b[33msched-fluxion-resource.debug[0]\u001b[0m: \u001b[34mresource status changed (rankset=[0-3] status=UP)\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.880523Z\u001b[0m \u001b[33msched-fluxion-resource.debug[0]\u001b[0m: \u001b[34mmod_main: resource graph database loaded\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998112Z\u001b[0m \u001b[33mbroker.debug[0]\u001b[0m: \u001b[34minsmod sched-fluxion-qmanager\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998336Z\u001b[0m \u001b[33msched-fluxion-qmanager.info[0]\u001b[0m: version 0.34.0-38-g0fad5268\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998452Z\u001b[0m \u001b[33msched-fluxion-qmanager.debug[0]\u001b[0m: \u001b[34mservice_register\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998472Z\u001b[0m \u001b[33msched-fluxion-qmanager.debug[0]\u001b[0m: \u001b[34menforced policy (queue=default): fcfs\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998477Z\u001b[0m \u001b[33msched-fluxion-qmanager.debug[0]\u001b[0m: \u001b[34meffective queue params (queue=default): queue-depth=4\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998478Z\u001b[0m \u001b[33msched-fluxion-qmanager.debug[0]\u001b[0m: \u001b[34meffective policy params (queue=default): default\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998726Z\u001b[0m \u001b[33msched-fluxion-qmanager.debug[0]\u001b[0m: \u001b[34mhandshaking with sched-fluxion-resource completed\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:18.998919Z\u001b[0m \u001b[33mjob-manager.debug[0]\u001b[0m: \u001b[34mscheduler: hello\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:19.000882Z\u001b[0m \u001b[33msched-fluxion-qmanager.debug[0]\u001b[0m: \u001b[34mrequeue success (queue=default id=1750450831360)\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:19.001022Z\u001b[0m \u001b[33mjob-manager.debug[0]\u001b[0m: \u001b[34mscheduler: ready unlimited\u001b[0m\n",
      "\u001b[32m2024-07-20T22:56:19.001141Z\u001b[0m \u001b[33msched-fluxion-qmanager.debug[0]\u001b[0m: \u001b[34mhandshaking with job-manager completed\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:03.486096Z\u001b[0m \u001b[33mkvs.debug[0]\u001b[0m: \u001b[34maggregated 2 transactions (2 ops)\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:03.487165Z\u001b[0m \u001b[33mkvs.debug[0]\u001b[0m: \u001b[34maggregated 2 transactions (2 ops)\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:03.749285Z\u001b[0m \u001b[33mkvs.debug[0]\u001b[0m: \u001b[34maggregated 3 transactions (3 ops)\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:03.752634Z\u001b[0m \u001b[33mkvs.debug[0]\u001b[0m: \u001b[34maggregated 2 transactions (2 ops)\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:15.324218Z\u001b[0m \u001b[33mjob-exec.debug[0]\u001b[0m: \u001b[34mexec aborted: id=∆í3VqVSHr7q\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:15.324274Z\u001b[0m \u001b[33mjob-exec.debug[0]\u001b[0m: \u001b[34mexec aborted: id=∆í3VqtrJWFh\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:15.324296Z\u001b[0m \u001b[33mjob-exec.debug[0]\u001b[0m: \u001b[34mexec aborted: id=∆í3VqzNXq8B\u001b[0m\n",
      "\u001b[32m2024-07-21T00:03:15.324309Z\u001b[0m \u001b[33mjob-exec.debug[0]\u001b[0m: \u001b[34mexec aborted: id=∆ínyvM4Nb\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!flux dmesg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3df1d-32c9-4996-b6f7-2fa85f4c02ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### flux start\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"background-color:lightgreen\">\n",
    "<span style=\"font-weight:600\">Description:</span> Interactively starting a set of resources\n",
    "</div>\n",
    "\n",
    "Sometimes you need to interactively start a set of compute resources. We call this subset a flux instance. You can launch jobs under this instance, akin to how you've done above! In fact, this entire tutorial is started (to give you 4 faux nodes) with a `flux start` command: \n",
    "\n",
    "```bash\n",
    "flux start --test-size=4\n",
    "```\n",
    "\n",
    "A Flux instance may be running as the default resource manager on a cluster, a job in a resource manager such as Slurm, LSF, or Flux itself, or as a test instance launched locally. This is really neat because it means you can launch Flux under other resource managers where it is not installed as the system workload manager. You can also execute \"one off\" commands to it, for example, to see the instance size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d568de50-f9e0-452f-8364-e52853013d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "!flux start --test-size=4 flux getattr size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693f2d9-651f-4f58-bf53-62528caa83d9",
   "metadata": {},
   "source": [
    "When you run `flux start` without a command, it will give you an interactive shell to the instance. When you provide a command (as we do above) it will run it and exit. This is what happens for the command above! The output indicates the number of brokers started successfully. As soon as we get and print the size, we exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997faffc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Python Submission API üêçÔ∏è\n",
    "Flux also provides first-class python bindings which can be used to submit jobs programmatically. \n",
    "\n",
    "### `flux.job.JobspecV1` to create job specifications\n",
    "\n",
    "Flux represents work as a standard called the [Jobspec](https://flux-framework.readthedocs.io/projects/flux-rfc/en/latest/spec_25.html). While you could write YAML or JSON, it's much easier to use provided Python functions that take high level metadata (command, resources, etc) to generate them. We can then replicate our previous example of submitting multiple heterogeneous jobs using these Python helpers, and testing that Flux co-schedules them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "third-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import flux\n",
    "from flux.job import JobspecV1\n",
    "from flux.job.JobID import JobID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "selective-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆í3Vyv4d99Z\n"
     ]
    }
   ],
   "source": [
    "# connect to the running Flux instance\n",
    "f = flux.Flux()\n",
    "\n",
    "# Create the Jobspec from a command to run a python script, and specify resources\n",
    "compute_jobreq = JobspecV1.from_command(\n",
    "    command=[\"./compute.py\", \"120\"], num_tasks=1, num_nodes=1, cores_per_task=1\n",
    ")\n",
    "\n",
    "# This is the \"current working directory\" (cwd)\n",
    "compute_jobreq.cwd = os.path.expanduser(\"~/flux-tutorial/flux-workflow-examples/job-submit-api/\")\n",
    "\n",
    "# When we submit, we get back the job identifier (JobID)\n",
    "print(JobID(flux.job.submit(f,compute_jobreq)).f58) # submit and print out the jobid (in f58 format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b260f-f08a-46ae-ad66-805911a857a7",
   "metadata": {},
   "source": [
    "Once we create the job, when we submit it in Python we get back a job identifier or jobid. We can then interact with the Flux handle, a connection to Flux, to get information about that job.\n",
    "\n",
    "### `flux.job.get_job(handle, jobid)` to get job info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed65cb46-8d8a-41f0-bec1-92b9a89e6db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâÔ∏è Hooray, we just submitted ∆í3VyvraktF!\n",
      "\n",
      "{\"t_depend\": 1721520202.4164655, \"t_run\": 0.0, \"t_cleanup\": 0.0, \"t_inactive\": 0.0, \"duration\": 0.0, \"expiration\": 0.0, \"name\": \"compute.py\", \"cwd\": \"/home/jovyan/flux-tutorial/flux-workflow-examples/job-submit-api/\", \"queue\": \"\", \"project\": \"\", \"bank\": \"\", \"ntasks\": 1, \"ncores\": 1, \"nnodes\": 1, \"priority\": 16, \"ranks\": \"\", \"nodelist\": \"\", \"success\": \"\", \"result\": \"\", \"waitstatus\": \"\", \"id\": 320116914913280, \"t_submit\": 1721520202.4053006, \"t_remaining\": 0.0, \"state\": \"SCHED\", \"username\": \"jovyan\", \"userid\": 1000, \"urgency\": 16, \"runtime\": 0.0, \"status\": \"SCHED\", \"returncode\": \"\", \"dependencies\": [], \"annotations\": {}, \"exception\": {\"occurred\": \"\", \"severity\": \"\", \"type\": \"\", \"note\": \"\"}}\n"
     ]
    }
   ],
   "source": [
    "# Let's submit again to retrieve (and save) the job identifier\n",
    "fluxjob = flux.job.submit(f, compute_jobreq)\n",
    "fluxjobid = JobID(fluxjob.f58)\n",
    "print(f\"üéâÔ∏è Hooray, we just submitted {fluxjobid}!\\n\")\n",
    "\n",
    "# Here is how to get your info. The first argument is the flux handle, then the jobid\n",
    "jobinfo = flux.job.get_job(f, fluxjobid)\n",
    "print(json.dumps(jobinfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ee252-dfc9-4256-8d45-df40718c5c3f",
   "metadata": {},
   "source": [
    "You can now run `flux jobs` to see the jobs that we submit from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d679897-7054-4f96-b340-7f39245aca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ∆í3VyvraktF jovyan   compute.py  F      1      1   0.014s 8660c254a8e5\n",
      "  ∆í3Vyv4d99Z jovyan   compute.py  F      1      1   0.020s 8660c254a8e5\n",
      "  ∆í2YnijmLwy jovyan   compute.py  F      1      1   0.031s 8660c254a8e5\n",
      "  ∆í2YiqfxNdm jovyan   compute.py  F      1      1   0.012s 8660c254a8e5\n",
      "  ∆í2YYgVHnyV jovyan   compute.py  F      1      1   0.062s 8660c254a8e5\n",
      "  ∆í2YYE7Ja9d jovyan   compute.py  F      1      1   0.048s 8660c254a8e5\n"
     ]
    }
   ],
   "source": [
    "!flux jobs -a | grep compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332f9c9",
   "metadata": {},
   "source": [
    "Under the hood, the `Jobspec` class is creating a YAML document that ultimately gets serialized as JSON and sent to Flux for ingestion, validation, queueing, scheduling, and eventually execution.  We can dump the raw JSON jobspec that is submitted, where we can see the exact resources requested and the task set to be executed on those resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efa06478",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"resources\": [\n",
      "    {\n",
      "      \"type\": \"node\",\n",
      "      \"count\": 1,\n",
      "      \"with\": [\n",
      "        {\n",
      "          \"type\": \"slot\",\n",
      "          \"count\": 1,\n",
      "          \"with\": [\n",
      "            {\n",
      "              \"type\": \"core\",\n",
      "              \"count\": 1\n",
      "            }\n",
      "          ],\n",
      "          \"label\": \"task\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"tasks\": [\n",
      "    {\n",
      "      \"command\": [\n",
      "        \"./compute.py\",\n",
      "        \"120\"\n",
      "      ],\n",
      "      \"slot\": \"task\",\n",
      "      \"count\": {\n",
      "        \"per_slot\": 1\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"attributes\": {\n",
      "    \"system\": {\n",
      "      \"duration\": 0,\n",
      "      \"cwd\": \"/home/jovyan/flux-tutorial/flux-workflow-examples/job-submit-api/\"\n",
      "    }\n",
      "  },\n",
      "  \"version\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(compute_jobreq.dumps(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8051640",
   "metadata": {},
   "source": [
    "### `FluxExecutor` for bulk submission\n",
    "\n",
    "We can use the FluxExecutor class to submit large numbers of jobs to Flux. This method uses python's `concurrent.futures` interface. Here is an example snippet from [flux-workflow-examples/async-bulk-job-submit/bulksubmit_executor.py](flux-workflow-examples/async-bulk-job-submit/bulksubmit_executor.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-trace",
   "metadata": {},
   "source": [
    "``` python \n",
    "with FluxExecutor() as executor:\n",
    "    compute_jobspec = JobspecV1.from_command(args.command)\n",
    "    futures = [executor.submit(compute_jobspec) for _ in range(args.njobs)]\n",
    "    # wait for the jobid for each job, as a proxy for the job being submitted\n",
    "    for fut in futures:\n",
    "    fut.jobid()\n",
    "    # all jobs submitted - print timings\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cleared-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulksubmit_executor: submitted 200 jobs in 0.16s. 1246.61job/s\n",
      "bulksubmit_executor: First job finished in about 0.172s\n",
      "|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (298.2 job/s)\n",
      "bulksubmit_executor: Ran 200 jobs in 0.8s. 249.6 job/s\n"
     ]
    }
   ],
   "source": [
    "# Submit the FluxExecutor based script.\n",
    "%run ./flux-workflow-examples/async-bulk-job-submit/bulksubmit_executor.py -n200 /bin/sleep 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e39506-7f89-4be2-880e-fc21cfe33548",
   "metadata": {},
   "source": [
    "### `flux.event_watch` to watch events\n",
    "\n",
    "If you want to get the output of a job (or more generally, stream events) you can do that as follows. Let's submit a quick job, and then look at the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b24124f8-0faf-4e99-83a5-bd983300fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721520256.00717: header {'version': 1, 'encoding': {'stdout': 'UTF-8', 'stderr': 'UTF-8'}, 'count': {'stdout': 1, 'stderr': 1}, 'options': {}}\n",
      "1721520256.01083: data {'stream': 'stderr', 'rank': '0', 'eof': True}\n",
      "1721520256.01085: data {'stream': 'stdout', 'rank': '0', 'data': 'Flux Plumbing üí©Ô∏èüöΩÔ∏è\\n'}\n",
      "1721520256.01087: data {'stream': 'stdout', 'rank': '0', 'eof': True}\n"
     ]
    }
   ],
   "source": [
    "# Create the Jobspec from a command to run a python script, and specify resources\n",
    "jobspec = JobspecV1.from_command(\n",
    "    command=[\"echo\", \"Flux Plumbing üí©Ô∏èüöΩÔ∏è\"], num_tasks=1, num_nodes=1, cores_per_task=1)\n",
    "jobid = flux.job.submit(f, jobspec)\n",
    "\n",
    "# Give some time to run and finish\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "for line in flux.job.event_watch(f, jobid, \"guest.output\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a6b44-4a37-4b75-9035-ade107def5de",
   "metadata": {},
   "source": [
    "### `flux.job.job_list` to list jobs\n",
    "\n",
    "Finally, it can be really helpful to get an entire listing of jobs. You can do that as follows. Note that the `job_list` is creating a remote procedure call (rpc) and we call `get` to retrieve the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d109d8-8586-4b91-bbfc-89e523199707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flux.job.job_list(f).get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3e767-0459-4218-a8cf-0f98bd32d6bf",
   "metadata": {},
   "source": [
    "# This concludes Chapter 1! üìóÔ∏è\n",
    "\n",
    "In this module, we covered:\n",
    "1. Submitting jobs with Flux\n",
    "2. The Flux Hierarchy\n",
    "3. Flux Process and Job Utilities\n",
    "4. Python Submission API\n",
    "\n",
    "To continue with the tutorial, open [Chapter 2](./02_flux_framework.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
